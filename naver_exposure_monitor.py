import os
import re
import json
import time
import csv
import socket
import shutil
import random
import logging
import tempfile
import threading
import struct
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
from urllib3.connection import HTTPConnection

import requests
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import (
    TimeoutException,
    WebDriverException,
)
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# =============================================================================
# 0) ì‚¬ìš©ì ì„¤ì •
# =============================================================================
MAX_THREADS = 1  

ENABLE_WINDOW_SIZE = True
WINDOW_WIDTH = 600
WINDOW_HEIGHT = 400
ENABLE_WINDOW_JITTER = False
WINDOW_JITTER_RANGE = 80
ENABLE_WINDOW_POSITION = True
WINDOW_POS_X = 50
WINDOW_POS_Y = 400
ENABLE_BLOCK_CHECK = False 
CHECK_INTERVAL_SECONDS = 60*30
MAX_PAGES = 10

TASKS = [
    {"keyword": "ì˜¬ë¹¼ë¯¸í‹°ë¹„", "domain": "https://www.tvda.co.kr/?srt=1"},
]

MAX_PROXIES_PER_TASK = 30
REFRESH_PROXIES_EACH_CYCLE = True
RUN_HEADLESS = False
PAGELOAD_TIMEOUT_SEC = 60*2
ELEM_WAIT_SEC = 30

# ğŸ”’ ìŠ¤í…”ìŠ¤ ëª¨ë“œ ì„¤ì • (ì‹ ê·œ ì¶”ê°€)
ENABLE_STEALTH = True  # ìŠ¤í…”ìŠ¤ ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€
RANDOM_DELAY_MIN = 2.0  # ì•¡ì…˜ ê°„ ìµœì†Œ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
RANDOM_DELAY_MAX = 5.0  # ì•¡ì…˜ ê°„ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
ENABLE_MOUSE_MOVEMENT = True  # ë§ˆìš°ìŠ¤ ì›€ì§ì„ ì‹œë®¬ë ˆì´ì…˜
SCROLL_BEHAVIOR = True  # ìŠ¤í¬ë¡¤ ì‹œë®¬ë ˆì´ì…˜

OUT_DIR = os.path.abspath("./naver_monitor_out")
LOG_FILE = os.path.join(OUT_DIR, "monitor.log")
RESULT_JSONL = os.path.join(OUT_DIR, "results.jsonl")
RESULT_CSV = os.path.join(OUT_DIR, "results.csv")
WINDOW_STATE_FILE = os.path.join(OUT_DIR, "window_states.json")  # ì°½ ìƒíƒœ ì €ì¥ íŒŒì¼
STOP_EVENT = threading.Event()
FILE_LOCK = threading.Lock()
WINDOW_STATE_LOCK = threading.Lock()  # ì°½ ìƒíƒœ íŒŒì¼ ì ‘ê·¼ìš© ë½ 

# =============================================================================
# 1) í”„ë¡ì‹œ ì„¤ì • (ê¸°ë³¸ ìœ ì§€)
# =============================================================================
ALL_SOURCES = [
    ("https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt", "http", False),
    ("https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/socks4.txt", "socks4", False),
    ("https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/socks5.txt", "socks5", False),
    ("https://raw.githubusercontent.com/victorgeel/proxy-list-update/main/proxies/http.txt", "http", False),
    ("https://raw.githubusercontent.com/victorgeel/proxy-list-update/main/proxies/socks4.txt", "socks4", False),
    ("https://raw.githubusercontent.com/victorgeel/proxy-list-update/main/proxies/socks5.txt", "socks5", False),
    ("https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/http.txt", "http", False),
    ("https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/socks4.txt", "socks4", False),
    ("https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/socks5.txt", "socks5", False),
]

SOURCES_KR = [
    # 1. ProxyScrape (êµ­ê°€ í•„í„° ì§€ì› - ê°€ì¥ ê°€ìš©ì„± ë†’ìŒ)
    #("https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=KR&ssl=all&anonymity=all", "http", False),
    #("https://api.proxyscrape.com/v2/?request=getproxies&protocol=socks4&timeout=10000&country=KR", "socks4", False),
    #("https://api.proxyscrape.com/v2/?request=getproxies&protocol=socks5&timeout=10000&country=KR", "socks5", False),

    # 2. Geonode (API ë°©ì‹ - í•œêµ­ IP ë°ì´í„° ì •ì œê°€ ì˜ ë¨)
    ("https://proxylist.geonode.com/api/proxy-list?limit=500&page=1&sort_by=lastChecked&sort_type=desc&country=KR&anonymityLevel=elite", "http", True),

    # 3. Spys.me (ì‹ ë¢°ë„ ë†’ì€ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¦¬ìŠ¤íŠ¸)
    #("https://spys.me/proxy.txt", "http", False), 

    # 4. Proxifly (êµ­ê°€ë³„ ëª©ë¡ ì§€ì›)
    #("https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/countries/KR/data.txt", "http", False),
]

#ALL_SOURCES = SOURCES_KR
HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}

linger_option = (socket.SOL_SOCKET, socket.SO_LINGER, struct.pack('ii', 1, 0))
HTTPConnection.default_socket_options = HTTPConnection.default_socket_options + [linger_option]

# =============================================================================
# 2) ë°ì´í„° ëª¨ë¸ ë° ìœ í‹¸ (ë¡œê·¸ ì„¤ì • ê°•í™”)
# =============================================================================
@dataclass
class ProxyInfo:
    protocol: str
    address: str
    source: str

@dataclass
class RunResult:
    ts: str
    keyword: str
    target_url: str
    proxy_protocol: Optional[str]
    proxy_address: Optional[str]
    proxy_source: Optional[str]
    found: bool
    found_page: Optional[int]
    found_rank_on_page: Optional[int]
    found_href: Optional[str]
    clicked_ok: bool
    final_url: Optional[str]
    error: Optional[str]
    note: Optional[str]

def setup_logging() -> None:
    os.makedirs(OUT_DIR, exist_ok=True)
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    # ë¡œê·¸ í¬ë§·ì— ì“°ë ˆë“œ ì´ë¦„ì„ ëª…ì‹œí•˜ì—¬ ì–´ë–¤ í‚¤ì›Œë“œ ì‘ì—…ì¸ì§€ êµ¬ë¶„ ê°€ëŠ¥í•˜ê²Œ í•¨
    fmt = logging.Formatter("%(asctime)s [%(levelname)s] [%(threadName)s] %(message)s", datefmt="%H:%M:%S")
    
    fh = logging.FileHandler(LOG_FILE, encoding="utf-8")
    fh.setFormatter(fmt)
    sh = logging.StreamHandler()
    sh.setFormatter(fmt)
    
    logger.handlers.clear()
    logger.addHandler(fh)
    logger.addHandler(sh)

# =============================================================================
# 2-1) ğŸ”’ ìŠ¤í…”ìŠ¤ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì‹ ê·œ ì¶”ê°€)
# =============================================================================
def load_window_state(slot_id: str) -> Optional[Dict]:
    """
    ìŠ¬ë¡¯ë³„ ì°½ ìœ„ì¹˜/í¬ê¸° ìƒíƒœ ë¡œë“œ
    """
    try:
        with WINDOW_STATE_LOCK:
            if os.path.exists(WINDOW_STATE_FILE):
                with open(WINDOW_STATE_FILE, 'r', encoding='utf-8') as f:
                    states = json.load(f)
                    return states.get(slot_id)
    except Exception as e:
        logging.warning(f"âš ï¸ ì°½ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨ (ìŠ¬ë¡¯ {slot_id}): {e}")
    return None

def save_window_state(slot_id: str, x: int, y: int, width: int, height: int) -> None:
    """
    ìŠ¬ë¡¯ë³„ ì°½ ìœ„ì¹˜/í¬ê¸° ìƒíƒœ ì €ì¥
    """
    try:
        with WINDOW_STATE_LOCK:
            states = {}
            if os.path.exists(WINDOW_STATE_FILE):
                with open(WINDOW_STATE_FILE, 'r', encoding='utf-8') as f:
                    states = json.load(f)
            
            states[slot_id] = {
                'x': x,
                'y': y,
                'width': width,
                'height': height
            }
            
            with open(WINDOW_STATE_FILE, 'w', encoding='utf-8') as f:
                json.dump(states, f, indent=2)
            
            logging.info(f"ğŸ’¾ ì°½ ìƒíƒœ ì €ì¥ ì™„ë£Œ (ìŠ¬ë¡¯ {slot_id}): ìœ„ì¹˜({x},{y}) í¬ê¸°({width}x{height})")
    except Exception as e:
        logging.warning(f"âš ï¸ ì°½ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨ (ìŠ¬ë¡¯ {slot_id}): {e}")

def random_delay(min_sec: float = None, max_sec: float = None) -> None:
    """
    ì¸ê°„ì²˜ëŸ¼ ë³´ì´ê¸° ìœ„í•œ ëœë¤ ë”œë ˆì´
    """
    if not ENABLE_STEALTH:
        return
    min_val = min_sec if min_sec is not None else RANDOM_DELAY_MIN
    max_val = max_sec if max_sec is not None else RANDOM_DELAY_MAX
    delay = random.uniform(min_val, max_val)
    time.sleep(delay)

def simulate_human_typing(element, text: str) -> None:
    """
    ì‚¬ëŒì²˜ëŸ¼ í•œ ê¸€ìì”© íƒ€ì´í•‘í•˜ëŠ” íš¨ê³¼
    """
    if not ENABLE_STEALTH:
        element.send_keys(text)
        return
    
    for char in text:
        element.send_keys(char)
        time.sleep(random.uniform(0.05, 0.15))  # ê¸€ìë‹¹ 50~150ms ë”œë ˆì´

def simulate_scroll(driver, scroll_count: int = 3) -> None:
    """
    í˜ì´ì§€ë¥¼ ì²œì²œíˆ ìŠ¤í¬ë¡¤í•˜ì—¬ ì¸ê°„ í–‰ë™ ì‹œë®¬ë ˆì´ì…˜
    """
    if not ENABLE_STEALTH or not SCROLL_BEHAVIOR:
        return
    
    for _ in range(scroll_count):
        scroll_amount = random.randint(200, 500)
        driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
        time.sleep(random.uniform(0.3, 0.8))

def get_random_user_agent() -> str:
    """
    ëœë¤ User-Agent ìƒì„± (ë‹¤ì–‘í•œ ë¸Œë¼ìš°ì € ë²„ì „)
    """
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    ]
    return random.choice(user_agents)

def inject_stealth_scripts(driver) -> None:
    """
    ğŸ”’ ê³ ê¸‰ ìŠ¤í…”ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ì£¼ì…
    - webdriver ì†ì„± ìˆ¨ê¹€
    - navigator ì†ì„± ì¡°ì‘
    - ìë™í™” ê°ì§€ ìš°íšŒ
    """
    if not ENABLE_STEALTH:
        return
    
    # 1. webdriver ì†ì„± ì œê±°
    stealth_js = """
    // webdriver ì†ì„± ìˆ¨ê¸°ê¸°
    Object.defineProperty(navigator, 'webdriver', {
        get: () => undefined
    });
    
    // Chrome ê´€ë ¨ ì†ì„± ì¶”ê°€
    window.chrome = {
        runtime: {}
    };
    
    // Permissions API ì¡°ì‘
    const originalQuery = window.navigator.permissions.query;
    window.navigator.permissions.query = (parameters) => (
        parameters.name === 'notifications' ?
            Promise.resolve({ state: Notification.permission }) :
            originalQuery(parameters)
    );
    
    // Plugin ë°°ì—´ ìˆ˜ì •
    Object.defineProperty(navigator, 'plugins', {
        get: () => [1, 2, 3, 4, 5]
    });
    
    // Languages ì„¤ì •
    Object.defineProperty(navigator, 'languages', {
        get: () => ['ko-KR', 'ko', 'en-US', 'en']
    });
    
    // WebGL Vendor ì •ë³´ ìˆ˜ì •
    const getParameter = WebGLRenderingContext.prototype.getParameter;
    WebGLRenderingContext.prototype.getParameter = function(parameter) {
        if (parameter === 37445) {
            return 'Intel Inc.';
        }
        if (parameter === 37446) {
            return 'Intel Iris OpenGL Engine';
        }
        return getParameter.apply(this, [parameter]);
    };
    
    // ìë™í™” ê°ì§€ ë©”ì„œë“œ ë®ì–´ì“°ê¸°
    window.navigator.chrome = {
        runtime: {},
    };
    
    // console.debug ìˆ¨ê¹€ (Selenium í”ì  ì œê±°)
    const originalDebug = console.debug;
    console.debug = function() {};
    """
    
    try:
        driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': stealth_js
        })
        logging.info("ğŸ”’ ìŠ¤í…”ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ì£¼ì… ì™„ë£Œ")
    except Exception as e:
        logging.warning(f"âš ï¸ ìŠ¤í…”ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ì£¼ì… ì‹¤íŒ¨ (undetected-chromedriverê°€ ì¼ë¶€ ì²˜ë¦¬): {e}")

# =============================================================================
# 3) í”„ë¡ì‹œ ìˆ˜ì§‘ ë° ê²€ì¦ (ê¸°ì¡´ ìœ ì§€)
# =============================================================================
def fetch_all_proxies() -> List[ProxyInfo]:
    logging.info("ğŸ“„ [ìˆ˜ì§‘] í”„ë¡ì‹œ ìˆ˜ì§‘ ì‹œì‘ (í…ìŠ¤íŠ¸/JSON í”„ë¡œí† ì½œ ë§¤ì¹­ ìµœì í™”)")
    raw_list = []
    
    for url, default_proto, _ in ALL_SOURCES:
        if STOP_EVENT.is_set(): break
        try:
            resp = requests.get(url, timeout=20, headers=HEADERS)
            if resp.status_code != 200: continue
            
            content = resp.text.strip()
            count = 0
            
            # 1ï¸âƒ£ JSON í˜•ì‹ (Geonode ë“±)
            if content.startswith('{') or content.startswith('['):
                try:
                    data = resp.json()
                    items = data.get('data', []) if isinstance(data, dict) else data
                    for item in items:
                        if isinstance(item, dict) and 'ip' in item and 'port' in item:
                            addr = f"{item['ip']}:{item['port']}"
                            # JSON ë‚´ protocols ìš°ì„  í™•ì¸, ì—†ìœ¼ë©´ ì†ŒìŠ¤ ì •ì˜ ê¸°ë³¸ê°’(default_proto) ì‚¬ìš©
                            actual_proto = default_proto
                            if 'protocols' in item and item['protocols']:
                                actual_proto = item['protocols'][0].lower()
                            
                            raw_list.append(ProxyInfo(protocol=actual_proto, address=addr, source=urlparse(url).netloc))
                            count += 1
                except: pass
            
            # 2ï¸âƒ£ ì¼ë°˜ í…ìŠ¤íŠ¸ í˜•ì‹ (í”„ë¡œí† ì½œ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ëŒ€ì‘)
            else:
                for line in content.splitlines():
                    line = line.strip()
                    if not line or line.startswith('#'): continue
                    
                    # ì£¼ì†Œë§Œ ìˆëŠ” ê²½ìš°(1.2.3.4:80)ë¥¼ ëŒ€ë¹„í•´ ë¬´ì¡°ê±´ default_proto ì ìš©
                    addr = line.split("://")[-1] if "://" in line else line
                    if ":" in addr:
                        # í…ìŠ¤íŠ¸ ëª©ë¡ì€ ì†ŒìŠ¤ ë¦¬ìŠ¤íŠ¸ ì˜†ì— ì ì–´ë‘” í”„ë¡œí† ì½œ(http, socks5 ë“±)ì„ ê°•ì œ ë¶€ì—¬
                        raw_list.append(ProxyInfo(protocol=default_proto, address=addr, source=urlparse(url).netloc))
                        count += 1
            
            if count > 0:
                logging.info(f"ğŸ“¥ [ìˆ˜ì§‘] {urlparse(url).netloc:20s} | {count:4d}ê°œ ({default_proto})")
                
        except Exception as e:
            logging.error(f"âš ï¸ [ì‹¤íŒ¨] {urlparse(url).netloc}: {e}")
            
    # ì¤‘ë³µ ì œê±°
    uniq = {(p.protocol, p.address): p for p in raw_list}
    proxies = list(uniq.values())
    logging.info(f"ğŸ“Š [ìµœì¢…] ì´ {len(proxies)}ê°œì˜ ê³ ìœ  í”„ë¡ì‹œ ë¡œë“œ ì™„ë£Œ")
    return proxies

def tcp_quick_check(addr: str, timeout: float = 2.0) -> bool:
    try:
        host, port_s = addr.split(":", 1)
        port = int(port_s)
        with socket.create_connection((host, port), timeout=timeout): return True
    except Exception: return False

# =============================================================================
# 4) ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ ìƒì„± (ğŸ”’ ìŠ¤í…”ìŠ¤ ê°•í™”)
# =============================================================================
def make_driver(proxy: Optional[ProxyInfo], slot_id: str = "0") -> Tuple[uc.Chrome, str]:
    profile_dir = tempfile.mkdtemp(prefix="naver_mon_profile_")
    options = uc.ChromeOptions()
    
    # ê¸°ë³¸ ì˜µì…˜
    options.add_argument(f"--user-data-dir={profile_dir}")
    options.add_argument("--no-first-run")
    options.add_argument("--no-default-browser-check")
    options.add_argument("--disable-popup-blocking")
    options.add_argument("--disable-notifications")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--no-sandbox")
    options.add_argument("--lang=ko-KR")
    
    # ğŸ”’ ìŠ¤í…”ìŠ¤ ì˜µì…˜ ì¶”ê°€
    if ENABLE_STEALTH:
        options.add_argument("--disable-blink-features=AutomationControlled")  # ìë™í™” ê°ì§€ ë¹„í™œì„±í™”
        options.add_argument("--disable-web-security")  # CORS ìš°íšŒ (ì„ íƒ)
        options.add_argument("--disable-features=IsolateOrigins,site-per-process")
        options.add_argument("--disable-infobars")
        options.add_argument("--disable-extensions")
        options.add_argument("--profile-directory=Default")
        options.add_argument("--ignore-certificate-errors")
        options.add_argument("--disable-gpu")  # GPU ê°€ì† ë¹„í™œì„±í™”
        
        # ëœë¤ User-Agent ì„¤ì •
        user_agent = get_random_user_agent()
        options.add_argument(f"--user-agent={user_agent}")
        logging.info(f"ğŸ­ ëœë¤ User-Agent ì ìš©: {user_agent[:50]}...")
    
    if RUN_HEADLESS: 
        options.add_argument("--headless=new")
    
    # í”„ë¡ì‹œ ì„¤ì •
    if proxy:
        proxy_str = f"{proxy.protocol}://{proxy.address}"
        logging.info(f"ğŸŒ [ë“œë¼ì´ë²„ ìƒì„±] í”„ë¡ì‹œ ì ìš©: {proxy_str} (ì¶œì²˜: {proxy.source})")
        options.add_argument(f"--proxy-server={proxy_str}")
    else:
        logging.info("ğŸŒ [ë“œë¼ì´ë²„ ìƒì„±] í”„ë¡ì‹œ ë¯¸ì‚¬ìš© (Direct ì—°ê²°)")

    # ë“œë¼ì´ë²„ ìƒì„±
    driver = uc.Chrome(options=options, use_subprocess=True)
    driver.set_page_load_timeout(PAGELOAD_TIMEOUT_SEC)
    
    # ğŸ”’ ìŠ¤í…”ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ì£¼ì…
    if ENABLE_STEALTH:
        inject_stealth_scripts(driver)
    
    # ğŸ“ ì €ì¥ëœ ì°½ ìƒíƒœ ë¡œë“œ ë° ì ìš©
    saved_state = load_window_state(slot_id)
    
    try:
        if saved_state:
            # ì €ì¥ëœ ìœ„ì¹˜ì™€ í¬ê¸°ê°€ ìˆìœ¼ë©´ ë³µì›
            logging.info(f"ğŸ“ ìŠ¬ë¡¯ {slot_id}: ì €ì¥ëœ ì°½ ìƒíƒœ ë³µì› ì¤‘... ìœ„ì¹˜({saved_state['x']},{saved_state['y']}) í¬ê¸°({saved_state['width']}x{saved_state['height']})")
            driver.set_window_size(saved_state['width'], saved_state['height'])
            driver.set_window_position(saved_state['x'], saved_state['y'])
        else:
            # ì €ì¥ëœ ìƒíƒœê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì • ì ìš©
            if ENABLE_WINDOW_SIZE:
                w, h = WINDOW_WIDTH, WINDOW_HEIGHT
                if ENABLE_WINDOW_JITTER:
                    w += random.randint(-WINDOW_JITTER_RANGE, WINDOW_JITTER_RANGE)
                    h += random.randint(-WINDOW_JITTER_RANGE, WINDOW_JITTER_RANGE)
                driver.set_window_size(max(300, w), max(300, h))
            if ENABLE_WINDOW_POSITION:
                driver.set_window_position(WINDOW_POS_X, WINDOW_POS_Y)
            logging.info(f"ğŸ“ ìŠ¬ë¡¯ {slot_id}: ê¸°ë³¸ ì°½ ì„¤ì • ì ìš©")
    except Exception as e:
        logging.warning(f"âš ï¸ ì°½ ì„¤ì • ì ìš© ì‹¤íŒ¨: {e}")
    
    return driver, profile_dir

def update_query_param(url: str, **kwargs) -> str:
    u = urlparse(url)
    q = parse_qs(u.query)
    for k, v in kwargs.items(): q[str(k)] = [str(v)]
    return urlunparse((u.scheme, u.netloc, u.path, u.params, urlencode(q, doseq=True), u.fragment))

# =============================================================================
# 5) ì‘ì—… ë¡œì§ (ğŸ”’ ìŠ¤í…”ìŠ¤ í–‰ë™ íŒ¨í„´ ì¶”ê°€)
# =============================================================================
def thread_worker(task: Dict, proxy: ProxyInfo, slot_id: str = "0"):
    keyword, target_url = task["keyword"], task["domain"]
    logging.info(f"â–¶ï¸ ì‘ì—… ì‹œì‘ | ìŠ¬ë¡¯: {slot_id} | í‚¤ì›Œë“œ: [{keyword}] | í”„ë¡ì‹œ: {proxy.address}")
    
    driver, profile_dir = None, ""
    rr = RunResult(datetime.now().isoformat(timespec="seconds"), keyword, target_url, proxy.protocol, proxy.address, proxy.source, False, None, None, None, False, None, None, None)
    
    try:
        # 1. TCP ì²´í¬
        if not tcp_quick_check(proxy.address):
            logging.warning(f"âŒ TCP ì—°ê²° ì‹¤íŒ¨: {proxy.address}")
            rr.error = "TCP_CONNECT_FAIL"
        else:
            logging.info(f"ğŸŒ ë¸Œë¼ìš°ì € ì‹¤í–‰ ì¤‘... (ìŠ¬ë¡¯ {slot_id}, í”„ë¡ì‹œ {proxy.address})")
            driver, profile_dir = make_driver(proxy, slot_id)
            
            # ğŸ”’ ì´ˆê¸° ë”œë ˆì´ (ë´‡ ê°ì§€ íšŒí”¼)
            random_delay(1.0, 2.0)
            
            logging.info(f"ğŸ” ë„¤ì´ë²„ ì ‘ì† ë° í‚¤ì›Œë“œ ê²€ìƒ‰: [{keyword}]")
            driver.get("https://www.naver.com/")
            WebDriverWait(driver, ELEM_WAIT_SEC).until(lambda d: d.execute_script("return document.readyState") in ("interactive", "complete"))
            
            # ğŸ”’ í˜ì´ì§€ ë¡œë”© í›„ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ê¸°
            random_delay(1.5, 3.0)
            
            # ğŸ”’ ìŠ¤í¬ë¡¤ ì‹œë®¬ë ˆì´ì…˜
            simulate_scroll(driver, scroll_count=2)
            
            box = WebDriverWait(driver, ELEM_WAIT_SEC).until(EC.presence_of_element_located((By.NAME, "query")))
            box.clear()
            
            # ğŸ”’ ì¸ê°„ì²˜ëŸ¼ íƒ€ì´í•‘
            simulate_human_typing(box, keyword)
            
            # ğŸ”’ ì—”í„° ì „ ì§§ì€ ëŒ€ê¸°
            random_delay(0.5, 1.0)
            box.send_keys(Keys.ENTER)
            
            WebDriverWait(driver, ELEM_WAIT_SEC).until(lambda d: "search.naver.com" in (d.current_url or ""))
            results_url = driver.current_url
            
            # ğŸ”’ ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            random_delay(2.0, 4.0)
            
            # 2. í˜ì´ì§€ ìˆœíšŒ
            for page in range(1, MAX_PAGES + 1):
                if STOP_EVENT.is_set(): break
                
                logging.info(f"ğŸ“„ í˜ì´ì§€ íƒìƒ‰ ì¤‘... ({page}/{MAX_PAGES} page)")
                driver.get(update_query_param(results_url, start=1 + (page - 1) * 10))
                
                # ğŸ”’ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                random_delay(2.0, 3.5)
                
                # ğŸ”’ ìŠ¤í¬ë¡¤ ì‹œë®¬ë ˆì´ì…˜
                simulate_scroll(driver, scroll_count=3)
                
                # íƒ€ê²Ÿ íƒìƒ‰
                found_data = None
                anchors = driver.find_elements(By.CSS_SELECTOR, "a[href]")
                for idx, a in enumerate(anchors, 1):
                    try:
                        href = a.get_attribute("href") or ""
                        # URL ì •ê·œí™” ë° ë¹„êµ
                        if href and target_url:
                            h_can = urlunparse((urlparse(href).scheme, urlparse(href).netloc, urlparse(href).path or "/", "", "", ""))
                            t_can = urlunparse((urlparse(target_url).scheme, urlparse(target_url).netloc, urlparse(target_url).path or "/", "", "", ""))
                            if h_can.lower() == t_can.lower():
                                found_data = (idx, href)
                                break
                    except: continue
                
                if found_data:
                    rank, href = found_data
                    logging.info(f"âœ¨ íƒ€ê²Ÿ ë°œê²¬! | {page}í˜ì´ì§€ {rank}ìœ„ | URL: {href[:50]}...")
                    rr.found, rr.found_page, rr.found_rank_on_page, rr.found_href = True, page, rank, href
                    
                    # ğŸ”’ í´ë¦­ ì „ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ê¸°
                    random_delay(1.0, 2.5)
                    
                    logging.info("ğŸ–±ï¸ íƒ€ê²Ÿ ë§í¬ í´ë¦­ ë° ê²€ì¦ ì¤‘...")
                    driver.get(href)
                    WebDriverWait(driver, 10).until(lambda d: d.execute_script("return document.readyState") in ("interactive", "complete"))
                    
                    # ğŸ”’ í˜ì´ì§€ ë„ì°© í›„ ëŒ€ê¸°
                    random_delay(2.0, 3.0)
                    
                    final_url = driver.current_url
                    # ìµœì¢… URL ê²€ì¦
                    h_final = urlunparse((urlparse(final_url).scheme, urlparse(final_url).netloc, urlparse(final_url).path or "/", "", "", ""))
                    t_can = urlunparse((urlparse(target_url).scheme, urlparse(target_url).netloc, urlparse(target_url).path or "/", "", "", ""))
                    
                    if h_final.lower() == t_can.lower():
                        logging.info(f"âœ… í´ë¦­ ì„±ê³µ: ìµœì¢… ëª©ì ì§€ í™•ì¸ë¨ ({h_final})")
                        rr.clicked_ok, rr.final_url = True, final_url
                    else:
                        logging.error(f"âš ï¸ ëª©ì ì§€ ë¶ˆì¼ì¹˜ | í˜„ì¬: {h_final}")
                        rr.clicked_ok, rr.final_url, rr.note = False, final_url, "FINAL_URL_NOT_MATCH"
                    break
                
                # ğŸ”’ ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°€ê¸° ì „ ëŒ€ê¸°
                if page < MAX_PAGES:
                    random_delay(1.5, 3.0)
            
            if not rr.found and not rr.error:
                logging.info(f"ğŸ” íƒìƒ‰ ì¢…ë£Œ: {MAX_PAGES}í˜ì´ì§€ ë‚´ì— íƒ€ê²Ÿì´ ì—†ìŠµë‹ˆë‹¤.")
                rr.error = "NOT_FOUND_IN_PAGES"

    except Exception as e:
        logging.error(f"ğŸ’¥ ì˜ˆì™¸ ë°œìƒ: {str(e)[:100]}")
        rr.error = str(e)[:160]
    finally:
        # ğŸ“ ì°½ ìƒíƒœ ì €ì¥ (ë“œë¼ì´ë²„ ì¢…ë£Œ ì „)
        if driver:
            try:
                pos = driver.get_window_position()
                size = driver.get_window_size()
                save_window_state(slot_id, pos['x'], pos['y'], size['width'], size['height'])
            except Exception as e:
                logging.warning(f"âš ï¸ ì°½ ìƒíƒœ ì¶”ì¶œ ì‹¤íŒ¨ (ìŠ¬ë¡¯ {slot_id}): {e}")
            
            try: driver.quit()
            except: pass
        
        if profile_dir: 
            try: shutil.rmtree(profile_dir, ignore_errors=True)
            except: pass
        
        # ë½ì„ ì‚¬ìš©í•œ ê²°ê³¼ ì €ì¥
        with FILE_LOCK:
            with open(RESULT_JSONL, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(rr), ensure_ascii=False) + "\n")
            is_new = not os.path.exists(RESULT_CSV)
            with open(RESULT_CSV, "a", newline="", encoding="utf-8") as f:
                w = csv.writer(f)
                if is_new: w.writerow(["ts", "keyword", "target_url", "proxy_protocol", "proxy_address", "proxy_source", "found", "found_page", "found_rank_on_page", "found_href", "clicked_ok", "final_url", "error", "note"])
                w.writerow([rr.ts, rr.keyword, rr.target_url, rr.proxy_protocol, rr.proxy_address, rr.proxy_source, rr.found, rr.found_page, rr.found_rank_on_page, rr.found_href, rr.clicked_ok, rr.final_url, rr.error, rr.note])
        
        status = "ì„±ê³µ" if rr.found else f"ì‹¤íŒ¨({rr.error})"
        logging.info(f"ğŸ ì‘ì—… ì¢…ë£Œ | ìŠ¬ë¡¯: {slot_id} | í‚¤ì›Œë“œ: [{keyword}] | ê²°ê³¼: {status}")

# =============================================================================
# 6) ë©”ì¸ ë£¨í”„
# =============================================================================
def main_loop() -> None:
    setup_logging()
    logging.info("==================================================")
    logging.info("ğŸš€ Naver Exposure Monitor ì‹œì‘")
    logging.info(f"âš™ï¸ ì„¤ì •: ì“°ë ˆë“œ ìŠ¬ë¡¯ {MAX_THREADS}ê°œ / íƒìƒ‰ {MAX_PAGES}í˜ì´ì§€")
    if ENABLE_STEALTH:
        logging.info(f"ğŸ”’ ìŠ¤í…”ìŠ¤ ëª¨ë“œ: í™œì„±í™” (ë”œë ˆì´: {RANDOM_DELAY_MIN}~{RANDOM_DELAY_MAX}ì´ˆ)")
    logging.info("==================================================")
    
    proxies_cache = []
    active_threads: List[threading.Thread] = []
    
    try:
        while not STOP_EVENT.is_set():
            if REFRESH_PROXIES_EACH_CYCLE or not proxies_cache: 
                proxies_cache = fetch_all_proxies()
            
            if not proxies_cache:
                logging.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œê°€ ì—†ìŠµë‹ˆë‹¤. 60ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                time.sleep(60); continue

            for task in TASKS:
                for idx, proxy in enumerate(proxies_cache):
                    if STOP_EVENT.is_set(): break
                    
                    # ìŠ¬ë¡¯ ëŒ€ê¸° ë¡œê¹…
                    if len(active_threads) >= MAX_THREADS:
                        logging.info(f"â³ ìŠ¬ë¡¯ ê°€ë“ ì°¼ìŒ ({len(active_threads)}/{MAX_THREADS}). ë¹ˆ ìŠ¬ë¡¯ ëŒ€ê¸° ì¤‘...")
                    
                    while len(active_threads) >= MAX_THREADS:
                        active_threads = [t for t in active_threads if t.is_alive()]
                        time.sleep(1)
                    
                    # ğŸ“ í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¬ë¡¯ ID ê³„ì‚° (0ë¶€í„° MAX_THREADS-1ê¹Œì§€)
                    used_slots = set()
                    for t in active_threads:
                        if t.is_alive() and '-slot' in t.name:
                            slot_part = t.name.split('-slot')[-1]
                            try:
                                used_slots.add(int(slot_part))
                            except: pass
                    
                    # ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ìŠ¬ë¡¯ ì°¾ê¸°
                    available_slot = None
                    for slot_num in range(MAX_THREADS):
                        if slot_num not in used_slots:
                            available_slot = slot_num
                            break
                    
                    if available_slot is None:
                        available_slot = len(active_threads)  # í´ë°±
                    
                    slot_id = str(available_slot)
                    
                    # ìƒˆ ì“°ë ˆë“œ ìƒì„± ë° ì‹¤í–‰ (ì“°ë ˆë“œ ì´ë¦„ì— ìŠ¬ë¡¯ ID í¬í•¨)
                    t_name = f"{task['keyword']}-{idx}-slot{slot_id}"
                    t = threading.Thread(target=thread_worker, args=(task, proxy, slot_id), name=t_name, daemon=True)
                    active_threads.append(t)
                    t.start()
                    logging.info(f"â• ìƒˆ ì“°ë ˆë“œ í• ë‹¹: [{t_name}] | ë‚¨ì€ ìŠ¬ë¡¯: {MAX_THREADS - len(active_threads)}")

            logging.info("â³ ëª¨ë“  ì‘ì—… íˆ¬ì… ì™„ë£Œ. í™œì„± ì“°ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸° ì¤‘...")
            while any(t.is_alive() for t in active_threads):
                active_threads = [t for t in active_threads if t.is_alive()]
                time.sleep(2)
                
            logging.info(f"âœ… ì‚¬ì´í´ ì™„ë£Œ. {CHECK_INTERVAL_SECONDS}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œì‘í•©ë‹ˆë‹¤.")
            time.sleep(CHECK_INTERVAL_SECONDS)
            
    except KeyboardInterrupt:
        STOP_EVENT.set()
        logging.info("ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ ì‹ í˜¸ ê°ì§€. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main_loop()