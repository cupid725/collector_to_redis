import os
import re
import json
import time
import csv
import socket
import shutil
import random
import logging
import tempfile
import threading
import struct
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
from urllib3.connection import HTTPConnection
from pathlib import Path

import requests
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import (
    TimeoutException,
    WebDriverException,
)
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# =============================================================================
# 0) ì‚¬ìš©ì ì„¤ì •
# =============================================================================
MAX_THREADS = 1  

ENABLE_WINDOW_SIZE = True
WINDOW_WIDTH = 1000
WINDOW_HEIGHT = 400
ENABLE_WINDOW_JITTER = False
WINDOW_JITTER_RANGE = 80
ENABLE_WINDOW_POSITION = True
WINDOW_POS_X = 50
WINDOW_POS_Y = 400
ENABLE_BLOCK_CHECK = False 
CHECK_INTERVAL_SECONDS = 60*30
MAX_PAGES = 10

TASKS = [
    {"keyword": "ì˜¬ë¹¼ë¯¸í‹°ë¹„", "domain": "https://www.tvda.co.kr/?srt=1"},
]

MAX_PROXIES_PER_TASK = 30
REFRESH_PROXIES_EACH_CYCLE = True
RUN_HEADLESS = False
PAGELOAD_TIMEOUT_SEC = 60*2
ELEM_WAIT_SEC = 30

# ğŸ”’ ìŠ¤í…”ìŠ¤ ëª¨ë“œ ì„¤ì • (ì‹ ê·œ ì¶”ê°€)
ENABLE_STEALTH = True  # ìŠ¤í…”ìŠ¤ ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€
RANDOM_DELAY_MIN = 2.0  # ì•¡ì…˜ ê°„ ìµœì†Œ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
RANDOM_DELAY_MAX = 5.0  # ì•¡ì…˜ ê°„ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
ENABLE_MOUSE_MOVEMENT = True  # ë§ˆìš°ìŠ¤ ì›€ì§ì„ ì‹œë®¬ë ˆì´ì…˜
SCROLL_BEHAVIOR = True  # ìŠ¤í¬ë¡¤ ì‹œë®¬ë ˆì´ì…˜

OUT_DIR = os.path.abspath("./naver_monitor_out")
LOG_FILE = os.path.join(OUT_DIR, "monitor.log")
RESULT_JSONL = os.path.join(OUT_DIR, "results.jsonl")
RESULT_CSV = os.path.join(OUT_DIR, "results.csv")
WINDOW_STATE_FILE = os.path.join(OUT_DIR, "window_states.json")  # ì°½ ìƒíƒœ ì €ì¥ íŒŒì¼
STOP_EVENT = threading.Event()
FILE_LOCK = threading.Lock()
WINDOW_STATE_LOCK = threading.Lock()  # ì°½ ìƒíƒœ íŒŒì¼ ì ‘ê·¼ìš© ë½ 

# ì „ì—­ ë³€ìˆ˜: ë‚´ ê³µì¸ IP ì €ì¥ìš©
MY_PUBLIC_IP = None

# =============================================================================
# 1) í”„ë¡ì‹œ ì„¤ì • (ê¸°ë³¸ ìœ ì§€)
# =============================================================================
ALL_SOURCES = [
    ("https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt", "http", False),
    ("https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/socks4.txt", "socks4", False),
    ("https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/socks5.txt", "socks5", False),
    ("https://raw.githubusercontent.com/victorgeel/proxy-list-update/main/proxies/http.txt", "http", False),
    ("https://raw.githubusercontent.com/victorgeel/proxy-list-update/main/proxies/socks4.txt", "socks4", False),
    ("https://raw.githubusercontent.com/victorgeel/proxy-list-update/main/proxies/socks5.txt", "socks5", False),
    ("https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/http.txt", "http", False),
    ("https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/socks4.txt", "socks4", False),
    ("https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/socks5.txt", "socks5", False),
]

SOURCES_KR = [
    ("https://proxylist.geonode.com/api/proxy-list?limit=500&page=1&sort_by=lastChecked&sort_type=desc&country=KR&anonymityLevel=elite", "http", True),
]

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}

linger_option = (socket.SOL_SOCKET, socket.SO_LINGER, struct.pack('ii', 1, 0))
HTTPConnection.default_socket_options = HTTPConnection.default_socket_options + [linger_option]

# =============================================================================
# 2) ë°ì´í„° ëª¨ë¸ ë° ìœ í‹¸ (ë¡œê·¸ ì„¤ì • ê°•í™”)
# =============================================================================
@dataclass
class ProxyInfo:
    protocol: str
    address: str
    source: str

@dataclass
class RunResult:
    ts: str
    keyword: str
    target_url: str
    proxy_protocol: Optional[str]
    proxy_address: Optional[str]
    proxy_source: Optional[str]
    found: bool
    found_page: Optional[int]
    found_rank_on_page: Optional[int]
    found_href: Optional[str]
    clicked_ok: bool
    final_url: Optional[str]
    error: Optional[str]
    note: Optional[str]

def setup_logging() -> None:
    os.makedirs(OUT_DIR, exist_ok=True)
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    fmt = logging.Formatter("%(asctime)s [%(levelname)s] [%(threadName)s] %(message)s", datefmt="%H:%M:%S")
    
    fh = logging.FileHandler(LOG_FILE, encoding="utf-8")
    fh.setFormatter(fmt)
    sh = logging.StreamHandler()
    sh.setFormatter(fmt)
    
    logger.handlers.clear()
    logger.addHandler(fh)
    logger.addHandler(sh)

# =============================================================================
# 2-1) ğŸ”’ ì¶”ê°€ëœ IP í™•ì¸ ë° ìŠ¤í…”ìŠ¤ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================
def get_my_actual_ip():
    """ì‹¤í–‰ ì‹œì ì˜ ë‚´ ì‹¤ì œ ê³µì¸ IP í™•ì¸"""
    try:
        res = requests.get("https://api.ipify.org", timeout=10)
        return res.text.strip()
    except:
        return None

def is_proxy_leaking_my_ip(proxy: ProxyInfo, my_ip: str):
    """í”„ë¡ì‹œê°€ ë‚´ IPë¥¼ ìœ ì¶œí•˜ê³  ìˆëŠ”ì§€(ë‚´ IPê°€ ë°˜í™˜ë˜ëŠ”ì§€) í™•ì¸"""
    if not my_ip: return False # ë‚´ IPë¥¼ ëª¨ë¥´ë©´ ì²´í¬ ë¶ˆê°€í•˜ë¯€ë¡œ íŒ¨ìŠ¤
    try:
        proxies = {
            "http": f"{proxy.protocol}://{proxy.address}",
            "https": f"{proxy.protocol}://{proxy.address}"
        }
        res = requests.get("https://api.ipify.org", proxies=proxies, timeout=10)
        return res.text.strip() == my_ip
    except:
        return False

def load_window_state(slot_id: str) -> Optional[Dict]:
    try:
        with WINDOW_STATE_LOCK:
            if os.path.exists(WINDOW_STATE_FILE):
                with open(WINDOW_STATE_FILE, 'r', encoding='utf-8') as f:
                    states = json.load(f)
                    return states.get(slot_id)
    except Exception as e:
        logging.warning(f"âš ï¸ ì°½ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨ (ìŠ¬ë¡¯ {slot_id}): {e}")
    return None

def save_window_state(slot_id: str, x: int, y: int, width: int, height: int) -> None:
    try:
        with WINDOW_STATE_LOCK:
            states = {}
            if os.path.exists(WINDOW_STATE_FILE):
                with open(WINDOW_STATE_FILE, 'r', encoding='utf-8') as f:
                    states = json.load(f)
            states[slot_id] = {'x': x, 'y': y, 'width': width, 'height': height}
            with open(WINDOW_STATE_FILE, 'w', encoding='utf-8') as f:
                json.dump(states, f, indent=2)
            logging.info(f"ğŸ’¾ ì°½ ìƒíƒœ ì €ì¥ ì™„ë£Œ (ìŠ¬ë¡¯ {slot_id}): ìœ„ì¹˜({x},{y}) í¬ê¸°({width}x{height})")
    except Exception as e:
        logging.warning(f"âš ï¸ ì°½ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨ (ìŠ¬ë¡¯ {slot_id}): {e}")

def random_delay(min_sec: float = None, max_sec: float = None) -> None:
    if not ENABLE_STEALTH: return
    min_val = min_sec if min_sec is not None else RANDOM_DELAY_MIN
    max_val = max_sec if max_sec is not None else RANDOM_DELAY_MAX
    time.sleep(random.uniform(min_val, max_val))

def simulate_human_typing(element, text: str) -> None:
    if not ENABLE_STEALTH:
        element.send_keys(text)
        return
    for char in text:
        element.send_keys(char)
        time.sleep(random.uniform(0.05, 0.15))

def simulate_scroll(driver, scroll_count: int = 3) -> None:
    if not ENABLE_STEALTH or not SCROLL_BEHAVIOR: return
    for _ in range(scroll_count):
        scroll_amount = random.randint(200, 500)
        driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
        time.sleep(random.uniform(0.3, 0.8))

def get_random_user_agent() -> str:
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    ]
    return random.choice(user_agents)

def inject_stealth_scripts(driver) -> None:
    if not ENABLE_STEALTH: return
    stealth_js = """
    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
    window.chrome = { runtime: {} };
    const originalQuery = window.navigator.permissions.query;
    window.navigator.permissions.query = (parameters) => (
        parameters.name === 'notifications' ?
            Promise.resolve({ state: Notification.permission }) :
            originalQuery(parameters)
    );
    Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3, 4, 5] });
    Object.defineProperty(navigator, 'languages', { get: () => ['ko-KR', 'ko', 'en-US', 'en'] });
    """
    try:
        driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {'source': stealth_js})
        logging.info("ğŸ”’ ìŠ¤í…”ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ì£¼ì… ì™„ë£Œ")
    except Exception as e:
        logging.warning(f"âš ï¸ ìŠ¤í…”ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ì£¼ì… ì‹¤íŒ¨: {e}")

# =============================================================================
# 3) í”„ë¡ì‹œ ìˆ˜ì§‘ ë° ê²€ì¦ (ê¸°ì¡´ ìœ ì§€)
# =============================================================================
def fetch_all_proxies() -> List[ProxyInfo]:
    logging.info("ğŸ“„ [ìˆ˜ì§‘] í”„ë¡ì‹œ ìˆ˜ì§‘ ì‹œì‘")
    raw_list = []
    for url, default_proto, _ in ALL_SOURCES:
        if STOP_EVENT.is_set(): break
        try:
            resp = requests.get(url, timeout=20, headers=HEADERS)
            if resp.status_code != 200: continue
            content = resp.text.strip()
            count = 0
            if content.startswith('{') or content.startswith('['):
                try:
                    data = resp.json()
                    items = data.get('data', []) if isinstance(data, dict) else data
                    for item in items:
                        if isinstance(item, dict) and 'ip' in item and 'port' in item:
                            addr = f"{item['ip']}:{item['port']}"
                            actual_proto = item['protocols'][0].lower() if 'protocols' in item and item['protocols'] else default_proto
                            raw_list.append(ProxyInfo(protocol=actual_proto, address=addr, source=urlparse(url).netloc))
                            count += 1
                except: pass
            else:
                for line in content.splitlines():
                    line = line.strip()
                    if not line or line.startswith('#'): continue
                    addr = line.split("://")[-1] if "://" in line else line
                    if ":" in addr:
                        raw_list.append(ProxyInfo(protocol=default_proto, address=addr, source=urlparse(url).netloc))
                        count += 1
            if count > 0:
                logging.info(f"ğŸ“¥ [ìˆ˜ì§‘] {urlparse(url).netloc:20s} | {count:4d}ê°œ ({default_proto})")
        except Exception as e:
            logging.error(f"âš ï¸ [ì‹¤íŒ¨] {urlparse(url).netloc}: {e}")
    uniq = {(p.protocol, p.address): p for p in raw_list}
    proxies = list(uniq.values())
    logging.info(f"ğŸ“Š [ìµœì¢…] ì´ {len(proxies)}ê°œì˜ ê³ ìœ  í”„ë¡ì‹œ ë¡œë“œ ì™„ë£Œ")
    return proxies

def tcp_quick_check(addr: str, timeout: float = 2.0) -> bool:
    try:
        host, port_s = addr.split(":", 1)
        port = int(port_s)
        with socket.create_connection((host, port), timeout=timeout): return True
    except Exception: return False

# =============================================================================
# 4) ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ ìƒì„± (ê¸°ì¡´ ìœ ì§€)
# =============================================================================
def make_driver(proxy: Optional[ProxyInfo], slot_id: str = "0") -> Tuple[uc.Chrome, str]:
    tmp_root = Path(__file__).resolve().parent / "_tmp_profiles"
    tmp_root.mkdir(parents=True, exist_ok=True)
    profile_dir = tempfile.mkdtemp(prefix=f"naver_mon_profile_", dir=str(tmp_root))

    driver = None
    try:
        options = uc.ChromeOptions()
        
        options.add_argument(f"--user-data-dir={profile_dir}")
        options.add_argument("--no-first-run")
        options.add_argument("--no-default-browser-check")
        options.add_argument("--disable-popup-blocking")
        options.add_argument("--disable-notifications")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--no-sandbox")
        options.add_argument("--lang=ko-KR")
        options.set_capability("pageLoadStrategy", "eager")   # âœ… í•µì‹¬
        
        if ENABLE_STEALTH:
            options.add_argument("--disable-blink-features=AutomationControlled")
            options.add_argument("--disable-web-security")
            options.add_argument("--disable-features=IsolateOrigins,site-per-process")
            options.add_argument("--disable-infobars")
            options.add_argument("--disable-extensions")
            options.add_argument("--profile-directory=Default")
            options.add_argument("--ignore-certificate-errors")
            options.add_argument("--disable-gpu")
            user_agent = get_random_user_agent()
            options.add_argument(f"--user-agent={user_agent}")
            logging.info(f"ğŸ­ ëœë¤ User-Agent ì ìš©: {user_agent[:50]}.")

        if RUN_HEADLESS:
            options.add_argument("--headless=new")

        if proxy:
            proxy_str = f"{proxy.protocol}://{proxy.address}"
            logging.info(f"ğŸŒ [ë“œë¼ì´ë²„ ìƒì„±] í”„ë¡ì‹œ ì ìš©: {proxy_str} (ì¶œì²˜: {proxy.source})")
            options.add_argument(f"--proxy-server={proxy_str}")

        driver = uc.Chrome(options=options, use_subprocess=True)
        driver.set_page_load_timeout(PAGELOAD_TIMEOUT_SEC)

        if ENABLE_STEALTH:
            inject_stealth_scripts(driver)

        saved_state = load_window_state(slot_id)
        try:
            if saved_state:
                driver.set_window_size(saved_state['width'], saved_state['height'])
                driver.set_window_position(saved_state['x'], saved_state['y'])
            else:
                if ENABLE_WINDOW_SIZE:
                    w, h = WINDOW_WIDTH, WINDOW_HEIGHT
                    if ENABLE_WINDOW_JITTER:
                        w += random.randint(-WINDOW_JITTER_RANGE, WINDOW_JITTER_RANGE)
                        h += random.randint(-WINDOW_JITTER_RANGE, WINDOW_JITTER_RANGE)
                    driver.set_window_size(max(300, w), max(300, h))
                if ENABLE_WINDOW_POSITION:
                    driver.set_window_position(WINDOW_POS_X, WINDOW_POS_Y)
        except Exception as e:
            logging.warning(f"âš ï¸ ì°½ ì„¤ì • ì ìš© ì‹¤íŒ¨: {e}")

        return driver, profile_dir

    except Exception as e:
        logging.error(f"ğŸ›‘ make_driver ì˜ˆì™¸ â†’ í”„ë¡œí•„ ì •ë¦¬ ì‹œë„: {e}")

        # ë“œë¼ì´ë²„ê°€ ì¼ë¶€ë¼ë„ ë–´ìœ¼ë©´ ë‹«ê¸°
        if driver:
            try:
                driver.quit()
            except:
                pass
            time.sleep(0.2)

        # í”„ë¡œí•„ ì‚­ì œ(ì¬ì‹œë„)
        for i in range(10):
            try:
                if profile_dir and os.path.exists(profile_dir):
                    shutil.rmtree(profile_dir)
                break
            except Exception as e2:
                logging.warning(f"âš ï¸ í”„ë¡œí•„ ì‚­ì œ ì‹¤íŒ¨(try {i+1}/10): {profile_dir} | {e2}")
                time.sleep(0.3 * (i + 1))

        raise


def make_driver_old(proxy: Optional[ProxyInfo], slot_id: str = "0") -> Tuple[uc.Chrome, str]:
    tmp_root = Path(__file__).resolve().parent / "_tmp_profiles"
    tmp_root.mkdir(parents=True, exist_ok=True)
    profile_dir = tempfile.mkdtemp(prefix=f"naver_mon_profile_", dir=str(tmp_root))
    
    options = uc.ChromeOptions()
    options.add_argument(f"--user-data-dir={profile_dir}")
    options.add_argument("--no-first-run")
    options.add_argument("--no-default-browser-check")
    options.add_argument("--disable-popup-blocking")
    options.add_argument("--disable-notifications")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--no-sandbox")
    options.add_argument("--lang=ko-KR")
    
    if ENABLE_STEALTH:
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--disable-web-security")
        options.add_argument("--disable-features=IsolateOrigins,site-per-process")
        options.add_argument("--disable-infobars")
        options.add_argument("--disable-extensions")
        options.add_argument("--profile-directory=Default")
        options.add_argument("--ignore-certificate-errors")
        options.add_argument("--disable-gpu")
        user_agent = get_random_user_agent()
        options.add_argument(f"--user-agent={user_agent}")
        logging.info(f"ğŸ­ ëœë¤ User-Agent ì ìš©: {user_agent[:50]}...")
    
    if RUN_HEADLESS: options.add_argument("--headless=new")
    if proxy:
        proxy_str = f"{proxy.protocol}://{proxy.address}"
        logging.info(f"ğŸŒ [ë“œë¼ì´ë²„ ìƒì„±] í”„ë¡ì‹œ ì ìš©: {proxy_str} (ì¶œì²˜: {proxy.source})")
        options.add_argument(f"--proxy-server={proxy_str}")

    #driver = uc.Chrome(options=options, use_subprocess=True)
    try:
        driver = uc.Chrome(options=options, use_subprocess=True)
    except Exception:
        # ë“œë¼ì´ë²„ ìƒì„± ë‹¨ê³„ì—ì„œ ì˜ˆì™¸ê°€ ë°œìƒí•˜ë©´ profile_dirì´ ëˆ„ìˆ˜ë˜ì§€ ì•Šë„ë¡ ì¦‰ì‹œ ì •ë¦¬
        try:
            shutil.rmtree(profile_dir, ignore_errors=True)
        except Exception:
            pass
    raise
    driver.set_page_load_timeout(PAGELOAD_TIMEOUT_SEC)
    
    if ENABLE_STEALTH: inject_stealth_scripts(driver)
    
    saved_state = load_window_state(slot_id)
    try:
        if saved_state:
            driver.set_window_size(saved_state['width'], saved_state['height'])
            driver.set_window_position(saved_state['x'], saved_state['y'])
        else:
            if ENABLE_WINDOW_SIZE:
                w, h = WINDOW_WIDTH, WINDOW_HEIGHT
                if ENABLE_WINDOW_JITTER:
                    w += random.randint(-WINDOW_JITTER_RANGE, WINDOW_JITTER_RANGE)
                    h += random.randint(-WINDOW_JITTER_RANGE, WINDOW_JITTER_RANGE)
                driver.set_window_size(max(300, w), max(300, h))
            if ENABLE_WINDOW_POSITION:
                driver.set_window_position(WINDOW_POS_X, WINDOW_POS_Y)
    except Exception as e:
        logging.warning(f"âš ï¸ ì°½ ì„¤ì • ì ìš© ì‹¤íŒ¨: {e}")
    return driver, profile_dir

def update_query_param(url: str, **kwargs) -> str:
    u = urlparse(url)
    q = parse_qs(u.query)
    for k, v in kwargs.items(): q[str(k)] = [str(v)]
    return urlunparse((u.scheme, u.netloc, u.path, u.params, urlencode(q, doseq=True), u.fragment))

def simulate_natural_scroll(driver, min_actions: int = 6, max_actions: int = 12) -> None:
    """
    ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° í–‰ë™ì²˜ëŸ¼:
    - ì•„ë˜ë¡œ ì—¬ëŸ¬ ë²ˆ ìŠ¤í¬ë¡¤
    - ì ê¹ ë©ˆì¶°ì„œ ì½ëŠ” ë“¯ ëŒ€ê¸°
    - ìœ„ë¡œ ì¡°ê¸ˆ ë˜ëŒì•„ê°€ëŠ” ìŠ¤í¬ë¡¤
    """
    if not ENABLE_STEALTH or not SCROLL_BEHAVIOR:
        return

    try:
        scroll_h = driver.execute_script(
            "return Math.max(document.body.scrollHeight, document.documentElement.scrollHeight) || 0;"
        )
        view_h = driver.execute_script("return window.innerHeight || 0;")
        if not scroll_h or not view_h:
            return
        if scroll_h <= view_h + 80:
            return  # ìŠ¤í¬ë¡¤í•  ê²Œ ê±°ì˜ ì—†ìŒ
    except Exception:
        return

    actions = random.randint(min_actions, max_actions)
    down_actions = max(2, int(actions * random.uniform(0.6, 0.8)))
    up_actions = max(1, actions - down_actions)

    # ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤ (ë¶€ë“œëŸ½ê²Œ)
    for _ in range(down_actions):
        step = random.randint(int(view_h * 0.25), int(view_h * 0.95))
        try:
            driver.execute_script(
                "window.scrollBy({top: arguments[0], left: 0, behavior: 'smooth'});",
                step,
            )
        except Exception:
            driver.execute_script("window.scrollBy(0, arguments[0]);", step)
        time.sleep(random.uniform(0.4, 1.2))

        # ì¤‘ê°„ì¤‘ê°„ 'ì½ëŠ”' ë©ˆì¶¤
        if random.random() < 0.25:
            time.sleep(random.uniform(0.7, 1.8))

    # ì ê¹ ë¨¸ë¬´ë¦„
    time.sleep(random.uniform(1.0, 2.5))

    # ìœ„ë¡œ ì¡°ê¸ˆ ë˜ëŒë¦¬ê¸°
    for _ in range(up_actions):
        step = random.randint(int(view_h * 0.15), int(view_h * 0.75))
        try:
            driver.execute_script(
                "window.scrollBy({top: -arguments[0], left: 0, behavior: 'smooth'});",
                step,
            )
        except Exception:
            driver.execute_script("window.scrollBy(0, -arguments[0]);", step)
        time.sleep(random.uniform(0.35, 1.0))

    # ë§ˆì§€ë§‰ì— ì•„ì£¼ ë¯¸ì„¸í•œ í”ë“¤ë¦¼(ê°€ë”)
    if random.random() < 0.5:
        jiggle = random.randint(-120, 120)
        driver.execute_script("window.scrollBy(0, arguments[0]);", jiggle)
        time.sleep(random.uniform(0.2, 0.6))

from selenium.webdriver.common.action_chains import ActionChains
def wait_and_mouse_click_live_more(driver, timeout=60):
    
    try :
        sel = (By.CSS_SELECTOR, "li a[href='/live-more']")

        # 1) í´ë¦­ ê°€ëŠ¥ ìƒíƒœê¹Œì§€ ëŒ€ê¸°
        elem = WebDriverWait(driver, timeout).until(EC.element_to_be_clickable(sel))

        # 2) í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ ìŠ¤í¬ë¡¤(ê°€ë” ì˜¤ë²„ë ˆì´/ê³ ì •í—¤ë” ë•Œë¬¸ì— í•„ìš”)
        driver.execute_script(
            "arguments[0].scrollIntoView({block:'center', inline:'center'});",
            elem
        )

        # 3) â€œë§ˆìš°ìŠ¤ë¡œâ€ ì´ë™ í›„ í´ë¦­
        ActionChains(driver).move_to_element(elem).pause(0.2).click(elem).perform()
        logging.info("ğŸ“¥ [ë™ì‘ ì„±ê³µ] /live-more") 
    except :
        logging.info("ğŸ“¥ [ë™ì‘ ì‹¤íŒ¨] /live-more") 
        return False
    
    return True

# =============================================================================
# 5) ì‘ì—… ë¡œì§ (IP ë…¸ì¶œ í•„í„°ë§ ê¸°ëŠ¥ í†µí•©)
# =============================================================================
def thread_worker(task: Dict, proxy: ProxyInfo, slot_id: str = "0"):
    keyword, target_url = task["keyword"], task["domain"]
    logging.info(f"â–¶ï¸ ì‘ì—… ì‹œì‘ | ìŠ¬ë¡¯: {slot_id} | í‚¤ì›Œë“œ: [{keyword}] | í”„ë¡ì‹œ: {proxy.address}")

    driver, profile_dir = None, ""
    rr = RunResult(
        datetime.now().isoformat(timespec="seconds"),
        keyword, target_url,
        proxy.protocol, proxy.address, proxy.source,
        False, None, None, None,
        False, None, None, None
    )

    try:
        # 1. TCP ì²´í¬ ë° ë‚´ IP ìœ ì¶œ ê²€ì‚¬
        if not tcp_quick_check(proxy.address):
            logging.warning(f"âŒ TCP ì—°ê²° ì‹¤íŒ¨: {proxy.address}")
            rr.error = "TCP_CONNECT_FAIL"

        elif is_proxy_leaking_my_ip(proxy, MY_PUBLIC_IP):
            logging.warning(f"âŒ í”„ë¡ì‹œ ê±°ë¶€ (ë‚´ ê³µì¸ IP ë…¸ì¶œë¨): {proxy.address}")
            rr.error = "IP_LEAK_DETECTED"

        else:
            logging.info(f"ğŸŒ ë¸Œë¼ìš°ì € ì‹¤í–‰ ì¤‘. (ìŠ¬ë¡¯ {slot_id})")
            driver, profile_dir = make_driver(proxy, slot_id)

            random_delay(1.0, 2.0)
            logging.info(f"ğŸ” ë„¤ì´ë²„ ì ‘ì† ë° í‚¤ì›Œë“œ ê²€ìƒ‰: [{keyword}]")
            driver.get("https://www.naver.com/")
            #WebDriverWait(driver, ELEM_WAIT_SEC).until(
            #    lambda d: d.execute_script("return document.readyState") in ("interactive", "complete")
            #)
            WebDriverWait(driver, ELEM_WAIT_SEC).until(
                lambda d: d.execute_script("return document.readyState") != "loading"
            )

            random_delay(1.5, 3.0)
            simulate_scroll(driver, scroll_count=2)

            box = WebDriverWait(driver, ELEM_WAIT_SEC).until(
                EC.presence_of_element_located((By.NAME, "query"))
            )
            box.clear()
            simulate_human_typing(box, keyword)
            random_delay(0.5, 1.0)
            box.send_keys(Keys.ENTER)

            WebDriverWait(driver, ELEM_WAIT_SEC).until(
                lambda d: "search.naver.com" in (d.current_url or "")
            )
            results_url = driver.current_url
            random_delay(2.0, 4.0)

            for page in range(1, MAX_PAGES + 1):
                if STOP_EVENT.is_set():
                    break

                logging.info(f"ğŸ“„ í˜ì´ì§€ íƒìƒ‰ ì¤‘. ({page}/{MAX_PAGES} page)")
                driver.get(update_query_param(results_url, start=1 + (page - 1) * 10))
                random_delay(2.0, 3.5)
                simulate_scroll(driver, scroll_count=3)

                found_data = None
                anchors = driver.find_elements(By.CSS_SELECTOR, "a[href]")

                # target canonicalì€ "ê°€ì¥ ë§ˆì§€ë§‰ ê³„ì‚°ê°’"ì„ ê·¸ëŒ€ë¡œ ì“°ì§€ ì•Šë„ë¡ ë°–ì—ì„œ ê´€ë¦¬
                t_can = urlunparse((
                    urlparse(target_url).scheme,
                    urlparse(target_url).netloc,
                    urlparse(target_url).path or "/",
                    "", "", ""
                )) if target_url else None

                for idx, a in enumerate(anchors, 1):
                    try:
                        href = a.get_attribute("href") or ""
                        if href and target_url:
                            h_can = urlunparse((
                                urlparse(href).scheme,
                                urlparse(href).netloc,
                                urlparse(href).path or "/",
                                "", "", ""
                            ))

                            if h_can.lower() == t_can.lower():
                                # âœ… elementê¹Œì§€ ê°™ì´ ì €ì¥ (ì‹¤ì œ í´ë¦­)
                                found_data = (idx, href, a)
                                break
                    except:
                        continue

                if found_data:
                    rank, href, elem = found_data
                    rr.found, rr.found_page, rr.found_rank_on_page, rr.found_href = True, page, rank, href
                    random_delay(1.0, 2.5)

                    # ===== (ë„ˆê°€ ìš”êµ¬í•œ í´ë¦­ ë¡œê·¸ ìŠ¤ë‹ˆí« ê·¸ëŒ€ë¡œ) =====
                    handles_before = driver.window_handles
                    url_before = driver.current_url

                    # í´ë¦­ì´ ê°€ë ¤ì ¸ì„œ ì•ˆë¨¹ëŠ” ì¼€ì´ìŠ¤ ì¤„ì´ê¸°
                    try:
                        driver.execute_script(
                            "arguments[0].scrollIntoView({block:'center', inline:'center'});",
                            elem
                        )
                    except:
                        pass
                    random_delay(0.3, 0.8)

                    elem.click()
                    logging.info(f"[Slot-{slot_id}] âœ… elem.click() executed")

                    # í´ë¦­ ê²°ê³¼ í™•ì¸(ìƒˆíƒ­/ì´ë™ ì—¬ë¶€)
                    time.sleep(0.2)
                    handles_after = driver.window_handles
                    url_after = driver.current_url

                    logging.info(
                        f"[Slot-{slot_id}] ğŸ” after click | handles: {len(handles_before)}â†’{len(handles_after)} | url: {url_before} â†’ {url_after}"
                    )
                    # ==============================================

                    # ìƒˆ íƒ­ì´ë©´ ì „í™˜í–ˆë‹¤ê°€, ì‘ì—… ëë‚˜ë©´ ë‹«ê³  ë¶€ëª¨ë¡œ ë³µê·€
                    parent_handle = driver.current_window_handle
                    child_handle = None
                    try:
                        new_handles = [h for h in handles_after if h not in handles_before]
                        if new_handles:
                            child_handle = new_handles[-1]
                            driver.switch_to.window(child_handle)
                    except:
                        child_handle = None

                    # í´ë¦­ í›„ ì‹¤ì œ ë¡œë”© ëŒ€ê¸°
                    #try:#

                    #    #WebDriverWait(driver, 10).until(
                    #    #    lambda d: d.execute_script("return document.readyState") != "loading"
                    #    #)
                    #    WebDriverWait(driver, 10).until(
                    #        EC.visibility_of_element_located((By.CSS_SELECTOR, "li a[href='/live-more']"))
                    #    )    
                    #except:
                    #    pass
                    # âœ… ë¡œë”© ëë‚˜ë©´ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ ë‹¤ìš´/ì—…
                    #random_delay(30.0, 60.0)
                    #simulate_natural_scroll(driver)
                    #random_delay(300.0, 360.0)
                    random_delay(30.0, 60.0)
                    
                    if not wait_and_mouse_click_live_more(driver):
                        rr.clicked_ok = False
                        rr.note = "LIVE_MORE_CLICK_FAILED"
                        rr.error = "LIVE_MORE_CLICK_FAILED"
                        return  # âœ… ì¦‰ì‹œ finallyë¡œ ê°
                    random_delay(30.0, 60.0)
                    simulate_natural_scroll(driver)
                    random_delay(300.0, 360.0)

                    final_url = driver.current_url
                    h_final = urlunparse((
                        urlparse(final_url).scheme,
                        urlparse(final_url).netloc,
                        urlparse(final_url).path or "/",
                        "", "", ""
                    ))

                    if t_can and h_final.lower() == t_can.lower():
                        rr.clicked_ok, rr.final_url = True, final_url
                    else:
                        rr.clicked_ok, rr.final_url, rr.note = False, final_url, "FINAL_URL_NOT_MATCH"

                    # ìì‹ íƒ­ì€ ë‹«ê³  ë¶€ëª¨ë¡œ ë³µê·€
                    if child_handle:
                        try:
                            driver.close()
                        except:
                            pass
                        try:
                            driver.switch_to.window(parent_handle)
                        except:
                            pass

                    break

                if page < MAX_PAGES:
                    random_delay(1.5, 3.0)

            if not rr.found and not rr.error:
                rr.error = "NOT_FOUND_IN_PAGES"

    except Exception as e:
        logging.error(f"ğŸ’¥ ì˜ˆì™¸ ë°œìƒ: {str(e)[:100]}")
        rr.error = str(e)[:160]

    finally:
        # ì°½ ìƒíƒœ ì €ì¥ + ë“œë¼ì´ë²„ ì¢…ë£Œ
        if driver:
            try:
                pos = driver.get_window_position()
                size = driver.get_window_size()
                save_window_state(slot_id, pos['x'], pos['y'], size['width'], size['height'])
            except:
                pass

            try:
                driver.quit()
            except:
                pass

            # quit ì§í›„ íŒŒì¼ë½ ì™„í™”
            time.sleep(0.3)

        # âœ… í”„ë¡œí•„ ë””ë ‰ ì‚­ì œ: ignore_errors ì œê±° + ì¬ì‹œë„ + ì‹¤íŒ¨ ë¡œê·¸
        if profile_dir:
            def _onerror(func, path, exc_info):
                try:
                    os.chmod(path, 0o777)
                    func(path)
                except:
                    pass

            deleted = False
            for i in range(10):
                try:
                    if os.path.exists(profile_dir):
                        shutil.rmtree(profile_dir, onerror=_onerror)
                    if not os.path.exists(profile_dir):
                        deleted = True
                        break
                except Exception as e2:
                    logging.warning(f"âš ï¸ í”„ë¡œí•„ ì‚­ì œ ì‹¤íŒ¨(try {i+1}/10): {profile_dir} | {e2}")
                time.sleep(0.3 * (i + 1))

            if not deleted and os.path.exists(profile_dir):
                logging.error(f"ğŸ›‘ í”„ë¡œí•„ ë””ë ‰ ìµœì¢… ì‚­ì œ ì‹¤íŒ¨: {profile_dir}")

        # ê²°ê³¼ ì €ì¥(ì›ë³¸ ê·¸ëŒ€ë¡œ)
        with FILE_LOCK:
            with open(RESULT_JSONL, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(rr), ensure_ascii=False) + "\n")
            is_new = not os.path.exists(RESULT_CSV)
            with open(RESULT_CSV, "a", newline="", encoding="utf-8") as f:
                w = csv.writer(f)
                if is_new:
                    w.writerow([
                        "ts", "keyword", "target_url", "proxy_protocol", "proxy_address", "proxy_source",
                        "found", "found_page", "found_rank_on_page", "found_href",
                        "clicked_ok", "final_url", "error", "note"
                    ])
                w.writerow([
                    rr.ts, rr.keyword, rr.target_url, rr.proxy_protocol, rr.proxy_address, rr.proxy_source,
                    rr.found, rr.found_page, rr.found_rank_on_page, rr.found_href,
                    rr.clicked_ok, rr.final_url, rr.error, rr.note
                ])

        logging.info(f"ğŸ ì‘ì—… ì¢…ë£Œ | ìŠ¬ë¡¯: {slot_id} | ê²°ê³¼: {'ì„±ê³µ' if rr.found else 'ì‹¤íŒ¨'}")


def thread_worker_old(task: Dict, proxy: ProxyInfo, slot_id: str = "0"):
    keyword, target_url = task["keyword"], task["domain"]
    logging.info(f"â–¶ï¸ ì‘ì—… ì‹œì‘ | ìŠ¬ë¡¯: {slot_id} | í‚¤ì›Œë“œ: [{keyword}] | í”„ë¡ì‹œ: {proxy.address}")
    
    driver, profile_dir = None, ""
    rr = RunResult(datetime.now().isoformat(timespec="seconds"), keyword, target_url, proxy.protocol, proxy.address, proxy.source, False, None, None, None, False, None, None, None)
    
    try:
        # 1. TCP ì²´í¬ ë° ë‚´ IP ìœ ì¶œ ê²€ì‚¬
        if not tcp_quick_check(proxy.address):
            logging.warning(f"âŒ TCP ì—°ê²° ì‹¤íŒ¨: {proxy.address}")
            rr.error = "TCP_CONNECT_FAIL"
        elif is_proxy_leaking_my_ip(proxy, MY_PUBLIC_IP):
            logging.warning(f"âŒ í”„ë¡ì‹œ ê±°ë¶€ (ë‚´ ê³µì¸ IP ë…¸ì¶œë¨): {proxy.address}")
            rr.error = "IP_LEAK_DETECTED"
        else:
            logging.info(f"ğŸŒ ë¸Œë¼ìš°ì € ì‹¤í–‰ ì¤‘... (ìŠ¬ë¡¯ {slot_id})")
            driver, profile_dir = make_driver(proxy, slot_id)
            
            random_delay(1.0, 2.0)
            logging.info(f"ğŸ” ë„¤ì´ë²„ ì ‘ì† ë° í‚¤ì›Œë“œ ê²€ìƒ‰: [{keyword}]")
            driver.get("https://www.naver.com/")
            WebDriverWait(driver, ELEM_WAIT_SEC).until(lambda d: d.execute_script("return document.readyState") in ("interactive", "complete"))
            
            random_delay(1.5, 3.0)
            simulate_scroll(driver, scroll_count=2)
            
            box = WebDriverWait(driver, ELEM_WAIT_SEC).until(EC.presence_of_element_located((By.NAME, "query")))
            box.clear()
            simulate_human_typing(box, keyword)
            random_delay(0.5, 1.0)
            box.send_keys(Keys.ENTER)
            
            WebDriverWait(driver, ELEM_WAIT_SEC).until(lambda d: "search.naver.com" in (d.current_url or ""))
            results_url = driver.current_url
            random_delay(2.0, 4.0)
            
            for page in range(1, MAX_PAGES + 1):
                if STOP_EVENT.is_set(): break
                logging.info(f"ğŸ“„ í˜ì´ì§€ íƒìƒ‰ ì¤‘... ({page}/{MAX_PAGES} page)")
                driver.get(update_query_param(results_url, start=1 + (page - 1) * 10))
                random_delay(2.0, 3.5)
                simulate_scroll(driver, scroll_count=3)
                
                found_data = None
                anchors = driver.find_elements(By.CSS_SELECTOR, "a[href]")
                for idx, a in enumerate(anchors, 1):
                    try:
                        href = a.get_attribute("href") or ""
                        if href and target_url:
                            h_can = urlunparse((urlparse(href).scheme, urlparse(href).netloc, urlparse(href).path or "/", "", "", ""))
                            t_can = urlunparse((urlparse(target_url).scheme, urlparse(target_url).netloc, urlparse(target_url).path or "/", "", "", ""))
                            if h_can.lower() == t_can.lower():
                                found_data = (idx, href)
                                break
                    except: continue
                
                if found_data:
                    rank, href = found_data
                    rr.found, rr.found_page, rr.found_rank_on_page, rr.found_href = True, page, rank, href
                    random_delay(1.0, 2.5)
                    driver.get(href)
                    WebDriverWait(driver, 10).until(lambda d: d.execute_script("return document.readyState") in ("interactive", "complete"))
                    random_delay(2.0, 3.0)
                    
                    final_url = driver.current_url
                    h_final = urlunparse((urlparse(final_url).scheme, urlparse(final_url).netloc, urlparse(final_url).path or "/", "", "", ""))
                    if h_final.lower() == t_can.lower():
                        rr.clicked_ok, rr.final_url = True, final_url
                    else:
                        rr.clicked_ok, rr.final_url, rr.note = False, final_url, "FINAL_URL_NOT_MATCH"
                    break
                
                if page < MAX_PAGES: random_delay(1.5, 3.0)
            
            if not rr.found and not rr.error:
                rr.error = "NOT_FOUND_IN_PAGES"

    except Exception as e:
        logging.error(f"ğŸ’¥ ì˜ˆì™¸ ë°œìƒ: {str(e)[:100]}")
        rr.error = str(e)[:160]
    finally:
        if driver:
            try:
                pos = driver.get_window_position()
                size = driver.get_window_size()
                save_window_state(slot_id, pos['x'], pos['y'], size['width'], size['height'])
            except: pass
            try: driver.quit()
            except: pass
        if profile_dir: shutil.rmtree(profile_dir, ignore_errors=True)
        
        with FILE_LOCK:
            with open(RESULT_JSONL, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(rr), ensure_ascii=False) + "\n")
            is_new = not os.path.exists(RESULT_CSV)
            with open(RESULT_CSV, "a", newline="", encoding="utf-8") as f:
                w = csv.writer(f)
                if is_new: w.writerow(["ts", "keyword", "target_url", "proxy_protocol", "proxy_address", "proxy_source", "found", "found_page", "found_rank_on_page", "found_href", "clicked_ok", "final_url", "error", "note"])
                w.writerow([rr.ts, rr.keyword, rr.target_url, rr.proxy_protocol, rr.proxy_address, rr.proxy_source, rr.found, rr.found_page, rr.found_rank_on_page, rr.found_href, rr.clicked_ok, rr.final_url, rr.error, rr.note])
        logging.info(f"ğŸ ì‘ì—… ì¢…ë£Œ | ìŠ¬ë¡¯: {slot_id} | ê²°ê³¼: {'ì„±ê³µ' if rr.found else 'ì‹¤íŒ¨'}")

# =============================================================================
# 6) ë©”ì¸ ë£¨í”„
# =============================================================================


def main_loop() -> None:
    global MY_PUBLIC_IP
    setup_logging()
    logging.info("==================================================")
    logging.info("ğŸš€ Naver Exposure Monitor ì‹œì‘")
    
    # ì‹œì‘ ì‹œ ë‚´ ì‹¤ì œ ê³µì¸ IPë¥¼ ë¨¼ì € í™•ì¸
    MY_PUBLIC_IP = get_my_actual_ip()
    logging.info(f"ğŸ  ë‚´ ê³µì¸ IP: {MY_PUBLIC_IP}")
    
    logging.info(f"âš™ï¸ ì„¤ì •: ì“°ë ˆë“œ ìŠ¬ë¡¯ {MAX_THREADS}ê°œ / íƒìƒ‰ {MAX_PAGES}í˜ì´ì§€")
    logging.info("==================================================")
    
    proxies_cache = []
    active_threads: List[threading.Thread] = []
    
    try:
        while not STOP_EVENT.is_set():
            if REFRESH_PROXIES_EACH_CYCLE or not proxies_cache: 
                proxies_cache = fetch_all_proxies()
            
            if not proxies_cache:
                logging.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œê°€ ì—†ìŠµë‹ˆë‹¤. 60ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                time.sleep(60); continue

            for task in TASKS:
                for idx, proxy in enumerate(proxies_cache):
                    if STOP_EVENT.is_set(): break
                    while len(active_threads) >= MAX_THREADS:
                        active_threads = [t for t in active_threads if t.is_alive()]
                        time.sleep(1)
                    
                    used_slots = set()
                    for t in active_threads:
                        if t.is_alive() and '-slot' in t.name:
                            try: used_slots.add(int(t.name.split('-slot')[-1]))
                            except: pass
                    
                    available_slot = None
                    for slot_num in range(MAX_THREADS):
                        if slot_num not in used_slots:
                            available_slot = slot_num
                            break
                    if available_slot is None: available_slot = 0
                    
                    slot_id = str(available_slot)
                    t_name = f"{task['keyword']}-{idx}-slot{slot_id}"
                    t = threading.Thread(target=thread_worker, args=(task, proxy, slot_id), name=t_name, daemon=True)
                    active_threads.append(t)
                    t.start()
                    logging.info(f"â• ìƒˆ ì“°ë ˆë“œ í• ë‹¹: [{t_name}]")

            while any(t.is_alive() for t in active_threads):
                active_threads = [t for t in active_threads if t.is_alive()]
                time.sleep(2)
            logging.info(f"âœ… ì‚¬ì´í´ ì™„ë£Œ. {CHECK_INTERVAL_SECONDS}ì´ˆ ëŒ€ê¸°...")
            time.sleep(CHECK_INTERVAL_SECONDS)
            
    except KeyboardInterrupt:
        STOP_EVENT.set()
        logging.info("ğŸ›‘ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == "__main__":
    main_loop()