import os
import argparse
import signal
import asyncio
import time
import random
import threading
import traceback
import math
import re
from urllib.parse import urlparse, urlunparse, parse_qs, urlencode, urlunparse, unquote
from typing import Optional
# Redis proxy lease client
from redis_proxy_lease import RedisProxyLeaseClient, RedisConnConfig
from PatchrightWrapper import StealthPatchrightBrowser

_TLS = threading.local()

def _ts() -> str:
    return time.strftime("%H:%M:%S")

def log(msg: str) -> None:
    slot = getattr(_TLS, 'slot_id', None)
    prefix = f"[Slot-{slot}] " if slot is not None else ""
    print(f"[{_ts()}] {prefix}{msg}", flush=True)

def _inc_global_click_count(n: int = 1) -> int:
    """ìŠ¬ë¡¯/ì“°ë ˆë“œ í•©ì‚° ì„±ê³µ(í´ë¦­) íšŸìˆ˜ ì¹´ìš´í„° ì¦ê°€ í›„ ì´í•© ë°˜í™˜."""
    global GLOBAL_CLICK_COUNT
    with GLOBAL_CLICK_LOCK:
        GLOBAL_CLICK_COUNT += int(n)
        return GLOBAL_CLICK_COUNT

# âœ… ê¸°ë³¸ ì„¤ì •
TARGET_URL = "https://bot.sannysoft.com/"
#TARGET_URL = "https://abrahamjuliot.github.io/creepjs/"
TARGET_URL = "https://www.naver.com/"
PROXY = "154.3.236.202:3128"
# ì˜ˆ)
# PROXY = "http://127.0.0.1:8888"
# PROXY = "http://user:pass@host:port"
# PROXY = "socks5://host:port"

TASKS = [
    #{"keyword": "ì˜¬ë¹¼ë¯¸í‹°ë¹„", "domain": "https://www.tvda.co.kr/?srt=1"},
    {"keyword": "í‚¹ì½©í‹°ë¹„", "domain": "https://www.kingkonglive.co.kr"},
]


# ===================== GLOBAL SUCCESS COUNTER =====================
GLOBAL_CLICK_COUNT = 0
GLOBAL_CLICK_LOCK = threading.Lock()


SLOT_WINDOW_LAYOUT = {}  # slot_id -> (x, y, w, h)

# ===================== Naver Search ì„¤ì • =====================
MAX_PAGES = 10
ELEM_WAIT_SEC = 30

def canonicalize_url(url: str) -> Optional[str]:
    try:
        if not url or "://" not in url:
            return None
        u = urlparse(url)
        scheme = (u.scheme or "https").lower()
        netloc = (u.netloc or "").lower()
        path = u.path or "/"
        return urlunparse((scheme, netloc, path, "", "", ""))
    except Exception:
        return None

def update_query_param(url: str, **kwargs) -> str:
    u = urlparse(url)
    q = parse_qs(u.query)
    for k, v in kwargs.items():
        q[str(k)] = [str(v)]
    return urlunparse((u.scheme, u.netloc, u.path, u.params, urlencode(q, doseq=True), u.fragment))

def extract_candidate_urls(href: str) -> list:
    """
    Naver ê²€ìƒ‰ ê²°ê³¼ hrefëŠ” ë¦¬ë‹¤ì´ë ‰íŠ¸/íŠ¸ë˜í‚¹ URLì¸ ê²½ìš°ê°€ ë§ì•„
    href ìì²´ + ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°(url/u/r/q ë“±) + í¼ì„¼íŠ¸ ì¸ì½”ë”©ëœ URLê¹Œì§€ í›„ë³´ë¡œ ì¶”ì¶œí•œë‹¤.
    """
    cands = []
    if not href:
        return cands

    # 1) href ìì²´
    cands.append(href)

    # 2) query param í›„ë³´
    try:
        u = urlparse(href)
        qs = parse_qs(u.query)
        for key in ("url", "u", "r", "q", "target", "to"):
            for v in qs.get(key, []):
                v = unquote(v)
                if v.startswith("http://") or v.startswith("https://"):
                    cands.append(v)
    except Exception:
        pass

    # 3) í¼ì„¼íŠ¸ ì¸ì½”ë”© URL íŒ¨í„´ ì¶”ì¶œ
    try:
        for m in re.findall(r"https?%3A%2F%2F[^&]+", href):
            v = unquote(m)
            if v.startswith("http://") or v.startswith("https://"):
                cands.append(v)
    except Exception:
        pass

    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    seen = set()
    uniq = []
    for x in cands:
        if x not in seen:
            seen.add(x)
            uniq.append(x)
    return uniq

def href_matches_target(href: str, target_url: str) -> bool:
    t_can = canonicalize_url(target_url)
    if not t_can:
        return False

    # í›„ë³´ URLë“¤ ì¤‘ í•˜ë‚˜ë¼ë„ canonicalì´ target canonicalê³¼ ê°™ìœ¼ë©´ ë§¤ì¹­
    for cand in extract_candidate_urls(href):
        h_can = canonicalize_url(cand)
        if h_can and h_can.lower() == t_can.lower():
            return True

        # netloc í¬í•¨ë§Œìœ¼ë¡œë„ ê°•í•œ íŒíŠ¸(íŠ¸ë˜í‚¹ URLì´ targetì„ í¬í•¨í•˜ëŠ” ì¼€ì´ìŠ¤)
        try:
            t_netloc = urlparse(t_can).netloc.lower()
            if t_netloc and t_netloc in cand.lower():
                return True
        except Exception:
            pass

    return False

async def human_scroll_to_locator(page, loc, max_steps: int = 20):
    """
    locatorê°€ í™”ë©´ì— ë³´ì´ë„ë¡ 'íœ 'ë¡œ ì¡°ê¸ˆì”© ìŠ¤í¬ë¡¤í•´ì„œ ì ‘ê·¼.
    - scroll_into_view_if_needed ê°™ì€ ìˆœê°„ ì í”„ë¥¼ í”¼í•¨
    """
    # locatorì˜ bounding boxë¥¼ ì–»ê¸° ìœ„í•´ ëª‡ ë²ˆ íŠ¸ë¼ì´
    box = None
    for _ in range(3):
        try:
            box = await loc.bounding_box()
            if box:
                break
        except Exception:
            pass
        await asyncio.sleep(random.uniform(0.05, 0.12))

    if not box:
        # boxë¥¼ ëª» ì–»ìœ¼ë©´ ìµœì†Œí•œì˜ fallback (ê·¸ëƒ¥ ì¡°ê¸ˆ ìŠ¤í¬ë¡¤)
        for _ in range(5):
            await page.mouse.wheel(0, random.randint(200, 520))
            await asyncio.sleep(random.uniform(0.08, 0.18))
        return

    # í˜„ì¬ ë·°í¬íŠ¸ ì¤‘ì•™ ê·¼ì²˜ë¡œ ëŒì–´ì˜¤ê¸° ìœ„í•´ ì—¬ëŸ¬ ë²ˆ íœ 
    viewport = page.viewport_size or {"width": 1280, "height": 720}
    target_y = box["y"] + box["height"] * 0.5
    center_y = viewport["height"] * 0.45  # ì‚´ì§ ìœ„ìª½ì— ë©ˆì¶”ëŠ” ëŠë‚Œ

    # í™”ë©´ ë°–ì´ë©´ deltaê°€ ì»¤ì§€ê³ , ê°€ê¹Œìš°ë©´ ì‘ê²Œ ì›€ì§ì´ë„ë¡
    for _ in range(max_steps):
        # boxëŠ” ìŠ¤í¬ë¡¤ í›„ ë°”ë€Œë¯€ë¡œ ê°±ì‹ 
        try:
            box = await loc.bounding_box()
        except Exception:
            box = None

        if not box:
            break

        target_y = box["y"] + box["height"] * 0.5
        delta = target_y - center_y

        # ì¶©ë¶„íˆ ê·¼ì ‘í•˜ë©´ ë©ˆì¶¤
        if abs(delta) < 80:
            break

        # í•œ ë²ˆì— ë„ˆë¬´ ë§ì´ ì•ˆ ì›€ì§ì´ê²Œ ì œí•œ + ëœë¤ì„±
        step = int(max(-700, min(700, delta * 0.65)))
        step += random.randint(-60, 60)

        await page.mouse.wheel(0, step)
        await asyncio.sleep(random.uniform(0.08, 0.22))

    # ë§ˆì§€ë§‰ ë¯¸ì„¸ì¡°ì •(ì‚¬ëŒì´ í•œ ë²ˆ ë” ì‚´ì§ íœ  í•˜ëŠ” ëŠë‚Œ)
    if random.random() < 0.6:
        await page.mouse.wheel(0, random.randint(-80, 140))
        await asyncio.sleep(random.uniform(0.06, 0.16))



async def wait_for_naver_search_box(page, timeout_ms: int = 20000):
    """ë„¤ì´ë²„ ë©”ì¸ì—ì„œ ê²€ìƒ‰ ì…ë ¥ì°½(ë˜ëŠ” ê²€ìƒ‰ UI)ì´ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°."""
    selectors = [
        "input#query",
        "input[name='query']",
        "div.search_input_box input",
        "input.search_input",
        "input[placeholder*='ê²€ìƒ‰']",
        "input[title*='ê²€ìƒ‰']",
        "input[aria-label*='ê²€ìƒ‰']",
    ]
    sel = ", ".join(selectors)
    try:
        await page.wait_for_selector(sel, timeout=timeout_ms, state="visible")
        return True
    except Exception:
        return False


async def wait_for_naver_results_page(page, timeout_ms: int = 30000) -> bool:
    """
    ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ 'ë„ì°©' íŒë³„:
    - wait_for_url(search.naver.com...) ëŒ€ì‹ , ê²°ê³¼ í˜ì´ì§€ pagination(1ë²ˆ) ë˜ëŠ” ê²°ê³¼ ì»¨í…Œì´ë„ˆë¥¼ ê¸°ë‹¤ë¦¼.
    """
    selectors = [
        # pagination '1' (í˜„ì¬ í˜ì´ì§€)
        'a.btn[role="button"][aria-pressed="true"]:has-text("1")',
        'a.btn[aria-pressed="true"]:has-text("1")',
        'a[aria-current="page"]:has-text("1")',
        # ê²°ê³¼ ì»¨í…Œì´ë„ˆ(ë ˆì´ì•„ì›ƒì´ ë°”ë€Œì–´ë„ ëŒ€ì²´ë¡œ ì¡´ì¬)
        "div#content",
        "div.api_subject_bx",
        "div.site_name",
    ]
    sel = ", ".join(selectors)
    try:
        await page.wait_for_selector(sel, timeout=timeout_ms, state="attached")
        return True
    except Exception:
        return False

async def naver_search_and_click(page, keyword: str, target_url: str) -> dict:
    """
    ë„¤ì´ë²„ ì ‘ì† â†’ ê²€ìƒ‰ â†’ ê²°ê³¼ í˜ì´ì§€ì—ì„œ target_url ë„ë©”ì¸ í´ë¦­
    ë°˜í™˜: dict(found, clicked, page, rank, href, final_url)
    """
    result = {
        "found": False,
        "clicked": False,
        "page": None,
        "rank": None,
        "href": None,
        "final_url": None,
        "note": None,
    }

    # 1) ë„¤ì´ë²„ ì ‘ì†
    log(f"[NAVER] goto https://www.naver.com/")
    #await page.goto("https://www.naver.com/", wait_until="domcontentloaded", timeout=60000*2)
    await page.goto("https://www.naver.com/", wait_until="commit", timeout=60000*2)

    # 2) ê²€ìƒ‰ì°½ ì°¾ê³  ê²€ìƒ‰
    log(f"[NAVER] search keyword='{keyword}'")
    search_selectors = [
        "input#query",
        "input[name='query']",
        "div.search_input_box input",
        "input.search_input",
        "input[placeholder*='ê²€ìƒ‰']",
        "input[title*='ê²€ìƒ‰']",
        "input[aria-label*='ê²€ìƒ‰']",
    ]

    # âœ… 1) ë©”ì¸ í˜ì´ì§€ì—ì„œ ê¸°ë‹¤ë ¤ì„œ ì°¾ê¸° (OR ì…€ë ‰í„°)
    box = None
    try:
        box = await page.wait_for_selector(", ".join(search_selectors), timeout=15_000)
    except Exception:
        box = None

    # âœ… 2) ê·¸ë˜ë„ ì—†ìœ¼ë©´ frame ì•ˆê¹Œì§€ ë’¤ì§€ê¸°
    if not box:
        for fr in page.frames:
            try:
                box = await fr.wait_for_selector(", ".join(search_selectors), timeout=2_000)
                if box:
                    break
            except Exception:
                continue

    if not box:
        log(f"[NAVER] âŒ search box not found | url={page.url}")
        # ë””ë²„ê¹…: inputë“¤ ë­ê°€ ìˆëŠ”ì§€ ì°ì–´ë³´ê¸°
        try:
            inputs = await page.evaluate("""
            () => [...document.querySelectorAll('input')].slice(0, 30).map(i => ({
            id: i.id, name: i.name, type: i.type, cls: i.className, placeholder: i.placeholder, title: i.title
            }))
            """)
            log(f"[NAVER] inputs(sample)={inputs}")
        except Exception as e:
            log(f"[NAVER] inputs dump fail: {e}")
        result["note"] = "SEARCH_BOX_NOT_FOUND"
        return result

    box = page.locator("input#query")
    await box.wait_for(state="visible", timeout=15000)
    await box.click()
    await box.press_sequentially(keyword, delay=random.randint(160, 320))
    await box.press("Enter")

    # 3) ê²°ê³¼ í˜ì´ì§€ ë„ì°© ëŒ€ê¸°
    ok = await wait_for_naver_results_page(page, timeout_ms=ELEM_WAIT_SEC * 1000 * 2)
    if not ok:
        log(f"[NAVER] âŒ results page not detected within {ELEM_WAIT_SEC}s | url={page.url} title={await page.title()}")
        raise TimeoutError(f"results page wait timeout ({ELEM_WAIT_SEC}s)")
    results_url = page.url
    log(f"[NAVER] results_url={results_url}")

    async def _go_to_page_by_click(target_page: int) -> bool:
        """
        ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í˜ì´ì§€ ë²ˆí˜¸/ë‹¤ìŒ ë²„íŠ¼ì„ 'í´ë¦­'í•´ì„œ ì´ë™.
        - Naver DOM/í´ë˜ìŠ¤ê°€ ë°”ë€” ìˆ˜ ìˆì–´ ì—¬ëŸ¬ ì…€ë ‰í„°ë¥¼ ìˆœì°¨ ì‹œë„
        - ìš”êµ¬ì‚¬í•­ìƒ URL ì§ì ‘ ì´ë™ì€ í•˜ì§€ ì•ŠìŒ(ì‹¤íŒ¨ ì‹œ False ë°˜í™˜)
        """
        if target_page <= 1:
            return True

        # í˜„ì¬ í˜ì´ì§€ ì¶”ì •(í™œì„± í˜ì´ì§€ ìˆ«ì)
        cur = 1
        try:
            for sel in [
                "div.sc_page_inner strong",
                "div.sc_page_inner a[aria-current='page']",
                "a[aria-current='page']",
                "strong[aria-current='page']",
            ]:
                loc = page.locator(sel)
                if await loc.count() > 0:
                    t = (await loc.first.inner_text()).strip()
                    if t.isdigit():
                        cur = int(t)
                        break
        except Exception:
            cur = 1

        if cur == target_page:
            return True

        # 1) í˜ì´ì§€ ìˆ«ì ë§í¬ ì§ì ‘ í´ë¦­ ì‹œë„(í˜„ì¬ í™”ë©´ì— ìˆì„ ë•Œ)
        try:
            # í˜ì´ì§€ë„¤ì´ì…˜ ì˜ì—­ ìš°ì„  íƒìƒ‰
            candidates = [
                f"div.sc_page_inner a:has-text('{target_page}')",
                f"a:has-text('{target_page}')",
            ]
            for sel in candidates:
                loc = page.locator(sel)
                if await loc.count() > 0:
                    #a = loc.first
                    #await a.scroll_into_view_if_needed(timeout=3000)
                    #await a.click()
                    a = loc.first
                    # âœ… ì‚¬ëŒì²˜ëŸ¼ íœ ë¡œ ìŠ¤í¬ë¡¤í•´ì„œ ê·¼ì²˜ê¹Œì§€ ì ‘ê·¼
                    await human_scroll_to_locator(page, a, max_steps=18)
                    # (ì„ íƒ) ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ê³  ì•½ê°„ ë¨¸ë­‡
                    try:
                        await a.hover()
                    except Exception:
                        pass
                    await asyncio.sleep(random.uniform(0.12, 0.35))

                    # âœ… í´ë¦­ë„ ì•½ê°„ ë”œë ˆì´
                    await a.click(delay=random.randint(30, 90))

                    try:
                        #await page.wait_for_load_state("domcontentloaded", timeout=60000)
                        await page.wait_for_load_state("commit", timeout=60000)
                    except Exception:
                        pass
                    return True
        except Exception:
            pass

        # 2) ë‹¤ìŒ ë²„íŠ¼ ë°˜ë³µ í´ë¦­
        steps = max(0, target_page - cur)
        next_selectors = [
            "a.btn_next",
            "a[aria-label*='ë‹¤ìŒ']",
            "a:has-text('ë‹¤ìŒ')",
            "button:has-text('ë‹¤ìŒ')",
        ]

        for _ in range(steps):
            clicked = False
            for sel in next_selectors:
                loc = page.locator(sel)
                try:
                    if await loc.count() > 0:
                        btn = loc.first
                        await human_scroll_to_locator(page, btn, max_steps=12)
                        try:
                            await btn.hover()
                        except Exception:
                            pass
                        await asyncio.sleep(random.uniform(0.10, 0.28))
                        await btn.click(delay=random.randint(30, 90))
                        clicked = True
                        try:
                            #await page.wait_for_load_state("domcontentloaded", timeout=60000)
                            await page.wait_for_load_state("commit", timeout=60000)
                        except Exception:
                            pass
                        break
                except Exception:
                    continue
            if not clicked:
                return False

        return True


    # 4) í˜ì´ì§€ ìˆœíšŒí•˜ë©° target ë§í¬ ì°¾ê¸°/í´ë¦­
    for p in range(1, MAX_PAGES + 1):
        if p == 1:
            log(f"[NAVER] scan page {p}/{MAX_PAGES} (current)")
        else:
            log(f"[NAVER] move to page {p}/{MAX_PAGES} by CLICK (no direct url nav)")
            ok = await _go_to_page_by_click(p)
            if not ok:
                log(f"[NAVER] âŒ failed to move to page {p} by click. stop scanning.")
                break
            log(f"[NAVER] scan page {p}/{MAX_PAGES} url={page.url}")

        anchors = page.locator("a[href]")
        try:
            total = await anchors.count()
        except Exception:
            total = 0

        # ë„ˆë¬´ ë§ì€ aë¥¼ ì „ë¶€ ëŒë©´ ëŠë ¤ì§ˆ ìˆ˜ ìˆì–´ ìƒí•œì„ ë‘ (í•„ìš”ì‹œ ëŠ˜ë ¤ë„ ë¨)
        limit = min(total, 600)

        for i in range(limit):
            a = anchors.nth(i)
            href = None
            try:
                href = await a.get_attribute("href")
            except Exception:
                continue

            if not href:
                continue

            if href_matches_target(href, target_url):
                result["found"] = True
                result["page"] = p
                result["rank"] = i + 1
                result["href"] = href
                log(f"[NAVER] âœ… found target on page={p} rank={i+1} href={href}")

                # í´ë¦­ (ìƒˆ íƒ­/ê°™ì€ íƒ­ ëª¨ë‘ ëŒ€ì‘) - âœ… ì‚¬ëŒì²˜ëŸ¼ ìŠ¤í¬ë¡¤/í˜¸ë²„/ë”œë ˆì´ í´ë¦­
                try:
                    await human_scroll_to_locator(page, a, max_steps=18)
                    try:
                        await a.hover()
                    except Exception:
                        pass
                    await asyncio.sleep(random.uniform(0.12, 0.35))
                except Exception:
                    pass

                ctx = page.context
                before_pages = list(ctx.pages)

                clicked_page = None
                try:
                    async with ctx.expect_page(timeout=2500) as pi:
                        await a.click(delay=random.randint(30, 90))
                    clicked_page = await pi.value
                    #await clicked_page.wait_for_load_state("domcontentloaded", timeout=60000)
                    await clicked_page.wait_for_load_state("commit", timeout=60000)
                    log(f"[NAVER] click opened new page url={clicked_page.url}")
                except Exception:
                    # same tab navigate
                    try:
                        await page.wait_for_load_state("commit", timeout=60000)
                    except Exception:
                        pass
                    clicked_page = page
                    log(f"[NAVER] click stayed in same page url={clicked_page.url}")

                result["clicked"] = True
                result["final_url"] = clicked_page.url
                return result

    result["note"] = "NOT_FOUND_IN_PAGES"
    log("[NAVER] âŒ target not found within pages")
    return result

# ===================== Redis ì„¤ì • (proxy lease) =====================
# (Redis ê´€ë ¨ ë¡œì§ì€ redis_proxy_lease.py ì˜ RedisProxyLeaseClientë¡œ ëª¨ë“ˆí™”)
REDIS_HOST = "127.0.0.1"
REDIS_PORT = 6379
REDIS_DB = 0
REDIS_PASSWORD = None




def _set_slot(slot_id: int):
    _TLS.slot_id = slot_id


def init_window_layout(args) -> None:
    """
    ì²˜ìŒ ì‹¤í–‰ ì‹œ ìŠ¬ë¡¯ë³„ 'ë¸Œë¼ìš°ì € ì˜ì—­'ì„ ê³ ì •ìœ¼ë¡œ ì‚°ì •í•´ SLOT_WINDOW_LAYOUTì— ì €ì¥.
    - ìŠ¬ë¡¯ì´ ì¬ì‹¤í–‰ë˜ì–´ë„ ê°™ì€ ìœ„ì¹˜ë¥¼ ìœ ì§€í•œë‹¤.
    - í•´ìƒë„ íƒì§€ ì—†ì´ tile_w/tile_h/cols ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•œë‹¤.
    """
    global SLOT_WINDOW_LAYOUT
    SLOT_WINDOW_LAYOUT = {}

    if args.slots <= 0:
        return

    # cols ìë™: ì§€ì •ê°’ ìš°ì„ , ì—†ìœ¼ë©´ sqrt ê¸°ë°˜ìœ¼ë¡œ ì ë‹¹íˆ ë°°ì¹˜
    cols = int(args.tile_cols) if int(args.tile_cols) > 0 else int(math.ceil(math.sqrt(args.slots)))
    cols = max(1, cols)

    w = int(args.tile_w)
    h = int(args.tile_h)
    gap = int(getattr(args, "tile_gap", 8))

    for slot_id in range(args.slots):
        col = slot_id % cols
        row = slot_id // cols
        x = col * (w + gap)
        y = row * (h + gap)
        SLOT_WINDOW_LAYOUT[slot_id] = (x, y, w, h)

    # ë¡œê·¸
    for slot_id, (x, y, w, h) in SLOT_WINDOW_LAYOUT.items():
        log(f"[WIN] reserved area slot={slot_id} x={x} y={y} w={w} h={h} cols={cols} gap={gap}")

async def run_one_session(slot_id: int, args) -> None:
    """
    ìŠ¬ë¡¯ 1íšŒ ì„¸ì…˜:
    - (ì˜µì…˜) Redisì—ì„œ í”„ë¡ì‹œ 1ê°œ claim
    - Patchright browser ì‹¤í–‰
    - TASKS ìˆ˜í–‰ (ë„¤ì´ë²„ ê²€ìƒ‰â†’ë„ë©”ì¸ í´ë¦­)
    - dwell í›„ ì¢…ë£Œ
    - Redis release/ban ì²˜ë¦¬
    """
    _set_slot(slot_id)

    redis_client: Optional[RedisProxyLeaseClient] = None
    proxy_member: Optional[str] = None
    session_ok = False
    local_proxy = args.proxy

    # (ì˜µì…˜) Redisì—ì„œ í”„ë¡ì‹œ ì„ëŒ€
    if args.proxy_from_redis:
        log(f"[REDIS] connecting host={args.redis_host}:{args.redis_port} db={args.redis_db} auth={'yes' if bool(args.redis_password) else 'no'}")
        try:
            redis_client = RedisProxyLeaseClient(
                RedisConnConfig(
                    host=args.redis_host,
                    port=int(args.redis_port),
                    db=int(args.redis_db),
                    password=args.redis_password,
                )
            )
            redis_client.connect()
            log("[REDIS] ping=OK")
        except Exception as e:
            log(f"[REDIS] ping=FAIL: {type(e).__name__}: {e}")
            return

        proxy_member = redis_client.claim(lease_seconds=int(args.lease_seconds), reclaim_limit=200, sample_k=50)
        if not proxy_member:
            log("[REDIS] ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œê°€ ì—†ì–´ ì¢…ë£Œí•¨.")
            try:
                redis_client.close()
            except Exception:
                pass
            return

        local_proxy = proxy_member
        log(f"[REDIS] âœ… proxy claimed: {proxy_member}")
        log(f"[REDIS] lease_seconds={args.lease_seconds} (member is expected to be like proto://ip:port)")

    try:
        log(f"[RUN] proxy_in_use={local_proxy}")

        # âœ… ìŠ¬ë¡¯ë³„ ì°½ ë°°ì¹˜(ë°ìŠ¤í¬í†±ì—ì„œë§Œ)
        extra_args = []
        if (not args.headless):
            if args.mobile:
                log("[WIN] tile_windows requested with mobile=True (best-effort; may be ignored by some setups)")
            w = int(args.tile_w)
            h = int(args.tile_h)
            cols = int(args.tile_cols) if args.tile_cols > 0 else max(1, args.slots)
            x = (slot_id % cols) * w
            y = (slot_id // cols) * h

            extra_args = [f"--window-size={w},{h}", f"--window-position={x},{y}"]
            log(f"[WIN] tile window pos=({x},{y}) size=({w},{h}) cols={cols}")


        browser = StealthPatchrightBrowser(
            proxy=local_proxy,
            webrtc_leak_protection=True,
            headless=args.headless,
            mobile=args.mobile,
            cleanup_user_data_dir=not args.keep_profile,
            extra_args=extra_args,
        )

        async with browser:
            page = await browser.new_page()
            # âœ… ì‚¬ìš©ìê°€ ë¸Œë¼ìš°ì €/íƒ­ì„ ë‹«ìœ¼ë©´ ì¦‰ì‹œ ì„¸ì…˜ ì¢…ë£Œë˜ë„ë¡ ê°ì‹œ
            closed_evt = asyncio.Event()
            try:
                page.on("close", lambda: closed_evt.set())
            except Exception:
                pass
            if getattr(browser, "selected_device_name", None):
                log(f"[DEVICE] selected={browser.selected_device_name}")
            else:
                log("[DEVICE] selected=(none)")

            # ìµœì´ˆ ì§„ì… URL
            t0 = time.time()
            log(f"[NAV] goto start wait_until=commit timeout={60000*3}ms url={args.url}")
            # âœ… í”„ë¡ì‹œê°€ ëŠë¦´ ìˆ˜ ìˆìœ¼ë‹ˆ 'commit'ê¹Œì§€ë§Œ ê¸°ë‹¤ë¦¬ê³ , í•„ìš”í•œ UI(ê²€ìƒ‰ì°½)ê°€ ëœ° ë•Œê¹Œì§€ ë³„ë„ ëŒ€ê¸°
            await page.goto(args.url, wait_until="commit", timeout=60000*3)

            ok = await wait_for_naver_search_box(page, timeout_ms=60000)
            if not ok:
                log(f"[NAV] âš ï¸ search box not visible within 20s (proxy slow or different page). url={page.url}")
            log(f"[NAV] goto done elapsed={time.time()-t0:.2f}s")
            log(f"[OK] ì ‘ì† ì™„ë£Œ: {args.url}")

            # âœ… TASKS ì‹¤í–‰
            any_clicked = False
            if TASKS:
                for idx, task in enumerate(TASKS, 1):
                    kw = task.get("keyword", "")
                    dom = task.get("domain", "")
                    log(f"[TASK] {idx}/{len(TASKS)} keyword='{kw}' domain='{dom}'")
                    try:
                        res = await naver_search_and_click(page, kw, dom)
                        log(f"[TASK] result found={res.get('found')} clicked={res.get('clicked')} page={res.get('page')} rank={res.get('rank')} final_url={res.get('final_url')}")
                        if res.get('clicked'):
                            total = _inc_global_click_count(1)
                            log(f"[COUNT] âœ… click success +1 -> total={total}")
                            any_clicked = True
                    except Exception as e:
                        log(f"[TASK] âŒ exception: {type(e).__name__}: {e}")
                        log(traceback.format_exc())

            # âœ… ì •ìƒì ìœ¼ë¡œ ì‘ì—…ì´ ëë‚˜ë©´(ë§í¬ í´ë¦­ê¹Œì§€ ì™„ë£Œ) 10ì´ˆ ëŒ€ê¸° í›„ ì„¸ì…˜ ì¢…ë£Œ
            wait_seconds = 10 if any_clicked else int(args.dwell_seconds)
            if wait_seconds > 0:
                if any_clicked:
                    log("[WAIT] task clicked -> 10ì´ˆ ëŒ€ê¸° í›„ ì„¸ì…˜ ì¢…ë£Œ")
                else:
                    log(f"[WAIT] {wait_seconds}ì´ˆ ëŒ€ê¸°... (ë¸Œë¼ìš°ì €ë¥¼ ë‹«ìœ¼ë©´ ì¦‰ì‹œ ë‹¤ìŒ ì„¸ì…˜)")
                try:
                    # pageê°€ ë‹«íˆë©´ waitê°€ ì¦‰ì‹œ í’€ë¦¼
                    if not page.is_closed():
                        await asyncio.wait_for(closed_evt.wait(), timeout=wait_seconds)
                        log("[WAIT] page closed by user -> end session now")
                except asyncio.TimeoutError:
                    pass
                except Exception:
                    # page ìƒíƒœ í™•ì¸ ì¤‘ ì˜ˆì™¸ê°€ ë‚˜ë©´ ì„¸ì…˜ ì¢…ë£Œë¡œ ê°„ì£¼
                    pass

        session_ok = True
        log("[RUN] session_ok=True")
        log(f"[ì„±ê³µíšŸìˆ˜] current_total={GLOBAL_CLICK_COUNT}")

    except Exception as e:
        log(f"[ERR] ì‹¤í–‰ ì¤‘ ì˜ˆì™¸: {type(e).__name__}: {e}")
        log(traceback.format_exc())

    finally:
        # âœ… Redis ë°˜ë‚©(ì„±ê³µ/ì‹¤íŒ¨ì— ë”°ë¼ cooldown/ban ì²˜ë¦¬)
        if redis_client and proxy_member:
            info = redis_client.release_on_result(
                proxy_member,
                session_ok=session_ok,
                cooldown_success=int(args.cooldown_success),
                cooldown_fail_base=int(args.cooldown_fail_base),
                cooldown_fail_jitter=int(args.cooldown_fail_jitter),
                max_fail=int(args.max_fail),
            )
            if info.get("action") == "banned":
                log(f"[REDIS] â›” proxy banned (fails={info.get('fails')}): {proxy_member}")
            else:
                if session_ok:
                    log(f"[REDIS] ğŸ”“ proxy released (ok): {proxy_member}")
                else:
                    log(f"[REDIS] ğŸ”“ proxy released (fail={info.get('fails')}, cooldown={info.get('cooldown')}s): {proxy_member}")
            try:
                redis_client.close()
            except Exception:
                pass



def _thread_entry(slot_id: int, args, stop_event: threading.Event):
    """
    ìš”êµ¬ì‚¬í•­:
      - slot=Nì´ë©´ slot[0..N-1] ê°ê°ì— 'ì“°ë ˆë“œ'ë¥¼ í•˜ë‚˜ ë„ì›€
      - ì“°ë ˆë“œê°€ ëë‚˜ë©´(1íšŒ ì„¸ì…˜ ì¢…ë£Œ) í•´ë‹¹ ìŠ¬ë¡¯ì— 'ìƒˆ ì“°ë ˆë“œ'ë¥¼ ë§Œë“¤ì–´ ë‹¤ì‹œ ì±„ì›€
      - ì´ë¥¼ ë°˜ë³µ
    """
    _set_slot(slot_id)
    if stop_event.is_set():
        return
    try:
        asyncio.run(run_one_session(slot_id, args))
    except Exception as e:
        log(f"[THREAD] fatal: {type(e).__name__}: {e}")
        log(traceback.format_exc())


def run_slot_supervisor(args):
    """
    ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ìŠ¬ë¡¯ ìƒíƒœë¥¼ ê°ì‹œí•˜ë©°,
    ë¹ˆ ìŠ¬ë¡¯ì´ ìƒê¸°ë©´ ìƒˆ ì“°ë ˆë“œë¥¼ ë§Œë“¤ì–´ ì±„ìš´ë‹¤.
    """
    stop_event = threading.Event()

    # slot_id -> (thread, run_count)
    threads = {i: None for i in range(args.slots)}
    run_counts = {i: 0 for i in range(args.slots)}

    def _spawn(slot_id: int):
        run_counts[slot_id] += 1
        t = threading.Thread(
            target=_thread_entry,
            args=(slot_id, args, stop_event),
            name=f"slot-{slot_id}-run-{run_counts[slot_id]}",
            daemon=True,
        )
        threads[slot_id] = t
        log(f"[SUP] spawn thread slot={slot_id} run={run_counts[slot_id]}")
        t.start()

    # ì´ˆê¸° ìŠ¤í°
    for i in range(args.slots):
        _spawn(i)

    try:
        while True:
            # ì¢…ë£Œ ì¡°ê±´: cycles > 0 ì´ë©´ ê° ìŠ¬ë¡¯ì´ cyclesë²ˆ ì„¸ì…˜ ëŒë©´ ì¢…ë£Œ
            if args.cycles > 0:
                done_slots = [i for i in range(args.slots) if run_counts[i] >= args.cycles and threads[i] and (not threads[i].is_alive())]
                if len(done_slots) == args.slots:
                    log("[SUP] all slots completed requested cycles. stop.")
                    break

            # ìŠ¬ë¡¯ ê°ì‹œ & ì¬ìŠ¤í°
            for i in range(args.slots):
                t = threads[i]
                if t is None:
                    _spawn(i)
                    continue

                if not t.is_alive():
                    # cycles ì œí•œì´ ìˆìœ¼ë©´, ë‹¤ ì°¼ìœ¼ë©´ ì¬ìŠ¤í° ì•ˆí•¨
                    if args.cycles > 0 and run_counts[i] >= args.cycles:
                        continue
                    _spawn(i)

            time.sleep(0.5)

    except KeyboardInterrupt:
        log("[SUP] KeyboardInterrupt. stopping ALL...")
        stop_event.set()
        # âœ… Ctrl+C ì¦‰ì‹œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ(ì“°ë ˆë“œ/í”Œë ˆì´wright ì •ë¦¬ ëŒ€ê¸° ì—†ì´)
        os._exit(0)

    finally:
        stop_event.set()
        # í˜„ì¬ ì‹¤í–‰ì¤‘ì¸ ì“°ë ˆë“œë“¤ join
        for i in range(args.slots):
            t = threads[i]
            if t and t.is_alive():
                log(f"[SUP] join slot={i} ...")
                t.join(timeout=10)
        log("[SUP] done.")


async def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--url", default=TARGET_URL)
    parser.add_argument("--proxy", default=PROXY)
    parser.add_argument("--mobile", action="store_true", help="ëª¨ë°”ì¼(Android) ë””ë°”ì´ìŠ¤ë§Œ ëœë¤ ì„ íƒ")
    parser.add_argument("--headless", action="store_true")
    parser.add_argument("--keep-profile", action="store_true", help="ìë™ ìƒì„± user_data_dir ì‚­ì œí•˜ì§€ ì•ŠìŒ")

    # âœ… Redisì—ì„œ í”„ë¡ì‹œ claim/release ì‚¬ìš©
    parser.add_argument("--proxy-from-redis", action="store_true", help="Redisì—ì„œ í”„ë¡ì‹œë¥¼ í•˜ë‚˜ ì„ëŒ€í•´ì„œ ì‚¬ìš© í›„ ë°˜ë‚©")
    parser.add_argument("--redis-host", default=REDIS_HOST)
    parser.add_argument("--redis-port", type=int, default=REDIS_PORT)
    parser.add_argument("--redis-db", type=int, default=REDIS_DB)
    parser.add_argument("--redis-password", default=REDIS_PASSWORD)

    # ìš´ì˜ íŒŒë¼ë¯¸í„°
    parser.add_argument("--lease-seconds", type=int, default=300)
    parser.add_argument("--cooldown-success", type=int, default=0)
    parser.add_argument("--cooldown-fail-base", type=int, default=30)
    parser.add_argument("--cooldown-fail-jitter", type=int, default=60)
    parser.add_argument("--max-fail", type=int, default=5)

    # âœ… ìŠ¬ë¡¯/ìŠ¤ë ˆë“œ ì˜µì…˜
    parser.add_argument("--slots", type=int, default=2, help="ë™ì‹œì— ëŒë¦´ ìŠ¬ë¡¯(ì“°ë ˆë“œ) ìˆ˜")
    parser.add_argument("--cycles", type=int, default=0, help="ê° ìŠ¬ë¡¯ì´ ì‹¤í–‰í•  ì„¸ì…˜ íšŸìˆ˜(0ì´ë©´ ë¬´í•œ ë°˜ë³µ)")

    # âœ… ëŒ€ê¸°(ê¸°ì¡´ ë™ì‘ ìœ ì§€: ê¸°ë³¸ 120ì´ˆ)
    parser.add_argument("--dwell-seconds", type=int, default=120)

    # âœ… ì°½ íƒ€ì¼ ë°°ì¹˜(ë°ìŠ¤í¬í†±ì—ì„œë§Œ)


    parser.add_argument("--tile-w", type=int, default=960)
    parser.add_argument("--tile-h", type=int, default=900)
    parser.add_argument("--tile-gap", type=int, default=8, help="ìŠ¬ë¡¯ ì°½ ì‚¬ì´ ê°„ê²©(px)")
    parser.add_argument("--tile-cols", type=int, default=0, help="íƒ€ì¼ ì»¬ëŸ¼ ìˆ˜(0ì´ë©´ slots ì‚¬ìš©)")

    args = parser.parse_args()
    # âœ… í•­ìƒ ì°½ íƒ€ì¼ ë°°ì¹˜ ì‚¬ìš©(ì˜µì…˜ ì œê±°)
    args.tile_windows = True

    # âœ… Ctrl+C ì¦‰ì‹œ ì¢…ë£Œ
    try:
        signal.signal(signal.SIGINT, lambda sig, frame: os._exit(0))
    except Exception:
        pass

    # main thread slot id None
    _TLS.slot_id = None
    log(f"[BOOT] url={args.url} | slots={args.slots} cycles={args.cycles} | mobile={args.mobile} | headless={args.headless} | keep_profile={args.keep_profile} | proxy_from_redis={args.proxy_from_redis}")

    # ìŠ¬ë¡¯ì´ 1ì´ë©´(ë‹¨ì¼) ê¸°ì¡´ì²˜ëŸ¼ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ê³  ì¢…ë£Œ(ë‹¨, cycles=0ì´ë©´ ë¬´í•œ)
    if args.slots <= 1:
        if args.cycles <= 0:
            # ë¬´í•œ ë°˜ë³µã„±
            n = 0
            while True:
                n += 1
                log(f"[SUP] single-slot loop n={n}")
                await run_one_session(0, args)
        else:
            for n in range(1, args.cycles + 1):
                log(f"[SUP] single-slot cycle {n}/{args.cycles}")
                await run_one_session(0, args)
        return

    # slots>1ì´ë©´ supervisorëŠ” ë™ê¸°(ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ê°ì‹œ)
    run_slot_supervisor(args)


if __name__ == "__main__":
    asyncio.run(main())
